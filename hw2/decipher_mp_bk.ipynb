{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Decipherment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import defaultdict, Counter\n",
    "import collections\n",
    "import pprint\n",
    "import math\n",
    "import bz2\n",
    "from ngram import *\n",
    "import sys, string, os\n",
    "import copy\n",
    "import pickle\n",
    "#from joblib import Parallel, delayed\n",
    "import itertools\n",
    "from multiprocessing import Process,Pool, cpu_count\n",
    "import datetime, time, random\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us read in the cipher text from the `data` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    if filename[-4:] == \".bz2\":\n",
    "        with bz2.open(filename, 'rt', encoding='utf8') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename, 'r', encoding='utf8') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    return content\n",
    "\n",
    "cipher = read_file(\"data/cipher.txt\")\n",
    "# print(cipher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the default solution we need to compute statistics like length, number of symbols/letters, \n",
    "unique occurences, frequencies and relative frequencies of a given file. This is done in the function `get_statistics` below.\n",
    "\n",
    "While using `get_statistics`, make sure that `cipher=True` is set when the input is a ciphertext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(content, cipher=True):\n",
    "    stats = {}\n",
    "    content = list(content)\n",
    "    split_content = [x for x in content if x != '\\n' and x!=' ']\n",
    "    length = len(split_content)\n",
    "    symbols = set(split_content)\n",
    "    uniq_sym = len(list(symbols))\n",
    "    freq = collections.Counter(split_content)\n",
    "    rel_freq = {}\n",
    "    for sym, frequency in freq.items():\n",
    "        rel_freq[sym] = (frequency/length)*100\n",
    "        \n",
    "    if cipher:\n",
    "        stats = {'content':split_content, 'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    else:\n",
    "        stats = {'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gold(gold_file):\n",
    "    with open(gold_file) as f:\n",
    "        gold = f.read()\n",
    "    f.close()\n",
    "    gold = list(gold.strip())\n",
    "    return gold\n",
    "\n",
    "def symbol_error_rate(dec, _gold):\n",
    "    gold = read_gold(_gold)\n",
    "    correct = 0\n",
    "    if len(gold) == len(dec):\n",
    "        for (d,g) in zip(dec, gold):\n",
    "            if d==g:\n",
    "                correct += 1\n",
    "    wrong = len(gold)-correct\n",
    "    error = wrong/len(gold)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cipher_desc = get_statistics(cipher, cipher=True)\n",
    "plaintxt = read_file(\"data/default.wiki.txt.bz2\")\n",
    "plaintxt_desc = get_statistics(plaintxt, cipher=False)\n",
    "#pp.pprint(cipher_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the 6-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 s, sys: 376 ms, total: 15.7 s\n",
      "Wall time: 15.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequence = 'In a few cases, a multilingual artifact has been necessary to facilitate decipherment, the Rosetta Stone being the classic example. Statistical techniques provide another pathway to decipherment, as does the analysis of modern languages derived from ancient languages in which undeciphered texts are written. Archaeological and historical information is helpful in verifying hypothesized decipherments.'\n",
    "\n",
    "# lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=True)\n",
    "lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.545382\n"
     ]
    }
   ],
   "source": [
    "# print(sequence)\n",
    "# lm_logprob = lm.score_seq(sequence)\n",
    "# print(\"TOTAL LM LOGPROB: {}\".format(lm_logprob), file=sys.stderr)\n",
    "# print(\"TOTAL LM LOGPROB: {}\".format(lm.score_seq('this is the text.')), file=sys.stderr)\n",
    "# print(lm.get_bitstring_spans('..oo...ooo..'))\n",
    "# print(lm.score_bitstring('thisisatest', 'ooooooooooo'))\n",
    "print(lm.score_bitstring('thisisatest', '...........'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation for Reference 3 to find the optimal extension order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the implementation of the reference 'Beam Search for Solving Substitution Ciphers'. The goal is to find the best extension order. As the paper mentioned, it is important to find a set of weights for the ngram order. I chose the weights \\[1,1,1,1,2,3\\] suggested by Anoop in a discussion post. I also tried several sets of weights. For beamsize of 10000, the result was not influenced quite much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the correct answer has been pruned out at a very early stage, it is not quite possible that the text can be fully deciphered since the following score is computed based on a wrong partial deciphered text. We tried several sets of weights to get different extension order results. But the results are pretty similar in terms of the orders. To try different orders, we pick all the ext_orders with different starting symbols. In the case of Zodiac, there are 5 candidate ext_order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sharp_n(cipher_desc, symbols_found, n_order):\n",
    "    '''\n",
    "    finds the #n for order n_order\n",
    "    cipher_desc -- cipher statistics\n",
    "    symbols_found -- list of single character string,\n",
    "                     specifies the list of symbols have been placed in the extention order\n",
    "    n_order -- int, specifies the order of n-gram\n",
    "    '''\n",
    "    sharp_n = 0\n",
    "    for i in range(len(cipher_desc['content'])-n_order+1):\n",
    "        for j in range(i, i+n_order, 1):\n",
    "            if cipher_desc['content'][j] not in symbols_found:\n",
    "                break\n",
    "            if j == (i+n_order-1):\n",
    "                sharp_n += 1\n",
    "                #print(cipher_desc['content'][i:i+n_order])\n",
    "    return sharp_n            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to test the find_sharp_n function above. The results should be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_str = 'ASCREAMINGCOMESACROSSTHESKY'\n",
    "# print(find_sharp_n(get_statistics(test_str), ['A','G','H','K','Y'],6))\n",
    "# find_sharp_n(get_statistics(test_str), ['S','C','E','M','O'],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a beam search to find the optimal extension order. The code below is pretty similar to the beam_search function. Most of the code is copied from it. For simplicity, the variable name might not quite make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ext_order(cipher_desc, topn=100, weights=[1,1,1,1,2,3]):\n",
    "    '''\n",
    "    finds the best order of deciphering cipher symbols (find best extention order)\n",
    "    cipher_desc -- cipher statistics\n",
    "    topn -- int, number of best trees we want to keep during iteration\n",
    "    weights -- list of int, weight for #n, n varies from 1 to 6\n",
    "    '''\n",
    "    # symbols already found with score\n",
    "    Hs = [([], 0)]\n",
    "    # hypothesis extended symbols with score\n",
    "    Ht = []\n",
    "    # initialize the cardinality (number of unique cipher text)\n",
    "    cardinality = 0\n",
    "    # if no weight is specified for unigram, use the most frequent symbol as the starting point\n",
    "    if weights[0] == 0:\n",
    "        cardinality += 1\n",
    "        Hs.append(([sorted(cipher_desc['frequencies'], key=cipher_desc['frequencies'].get, reverse=True)[0]], 0))\n",
    "    # list of cipher symbols\n",
    "    Ve = sorted(cipher_desc['frequencies'], key=cipher_desc['frequencies'].get, reverse=True)\n",
    "    while cardinality < cipher_desc['vocab_length']:\n",
    "        for phi, previous_score in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = copy.deepcopy(phi)\n",
    "                if e in phi_prime:\n",
    "                    continue\n",
    "                else:\n",
    "                    phi_prime.append(e)\n",
    "                    this_score = 0\n",
    "                    for i in range(len(weights)):\n",
    "                        this_score += weights[i]*find_sharp_n(cipher_desc, phi_prime, i+1)\n",
    "                    Ht.append((phi_prime, this_score))\n",
    "        # prune the histogram\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]                    \n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "#         if cardinality <= 5:\n",
    "#             print(Hs)\n",
    "        #print('Done with symbol number', cardinality, '; Current best score: ', Hs[0][1])\n",
    "        #print('Hs', Hs)\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 20s, sys: 0 ns, total: 3min 20s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ext_orders = find_ext_order(cipher_desc, topn=100, weights=[1,1,1,1,2,3])\n",
    "\n",
    "seen_first_symbols = []\n",
    "candidate_orders = []\n",
    "for item in ext_orders:\n",
    "    if item[0][0] not in seen_first_symbols:\n",
    "        seen_first_symbols.append(item[0][0])\n",
    "        candidate_orders.append(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext_order = ['P', 'B', '∑', 'º', '∫', '/', 'Z', 'u', 'A',\n",
    "#  '∆', 'O', 'R', 'À', 'V', '–', '•', 'X', 'W',\n",
    "#  '§', 'π', '≈', '—', '+', 'D', 'G', '√', 'E',\n",
    "#  'K', 'y', 'æ', 'Ã', 'I', 'H', 'F', '∞', '“',\n",
    "#  'µ', 'Q', '£', 'M', 'Ç', 'J', '^', 'L', '∏',\n",
    "#  'ƒ', 'S', 'T', '‘', 'N', '¢', '\\\\', 'Ω',\n",
    "#  'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ext_order.pkl', 'wb') as fh:\n",
    "#     pickle.dump(ext_orders, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ext_order.pkl', 'rb') as fh:\n",
    "#     ext_order = pickle.load(fh, encoding='utf8')[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline with better extension order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first change I made to the baseline was to rewrite the score function to optimize the running speed. The change I made is to score the newly fixed symbol plantext character pair and corresponding influenced previously fixed plantext character based on the previous score instead of scoring the whole bitstring in each iteration. For instance, 'oooo...o' -> 'oooo..xo'. The new score can be calculated by adding unigram score of 'x' to the previous score, substracting unigram score of 'o' following 'x' and bigram score of '<\\s>' from the previous score, and adding bigram score of 'o' following 'x' and trigram score of '<\\s>' to the previous score. With this approach, the running time was improved to 20 minitues from 1 hour with a beamsize of 10000 on my machine with i7 7700k cpu. And the computed score is almost same as the score computed with score_bit_string function (the difference is within 0.0000001). Another approach to speed up the whole process we tried is multiprocessing. We will talk about that in the following notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(cipher, phi, new_f, new_e, previous_score):\n",
    "    '''\n",
    "    scores the phi_prime based on the previous score, returns a float\n",
    "    cipher -- list of single character string\n",
    "    phi -- dictionary, old mapping e->[f]\n",
    "    new_f -- single-character string, extended symbol\n",
    "    previous_score -- float, old score for phi\n",
    "    '''\n",
    "    mapping = phi\n",
    "    new_score = previous_score\n",
    "    # for the first iteration, the previous score should be -2.545382 instead of 0\n",
    "    # this is because the score of an empty string is not 0 whiling scoring with bitstring\n",
    "    # the value can be obtained by calling lm.score_bitstring('thisisatest', '...........')\n",
    "    if len(phi)==0:\n",
    "        new_score += -2.545382\n",
    "    lm_state = lm.begin()\n",
    "    old_lm_state = lm.begin()\n",
    "    # this Flag is used to track if a newly-fixed character affects the previously-fixed character\n",
    "    triggerChangeFlag = 0\n",
    "    for i in range(len(cipher)):\n",
    "        char = cipher[i]\n",
    "        # if this is a previously fixed character and not influenced by the newly-fixed character\n",
    "        # we only need to track the lm_state and old lm_state, no need to compute the score\n",
    "        if (char in mapping.keys()) and (triggerChangeFlag==0):\n",
    "            token = mapping[char]\n",
    "            ngram = lm_state + (token,)\n",
    "            while len(ngram)> 0:\n",
    "                if ngram in lm.table:\n",
    "                    lm_state = ngram[-lm.history:]\n",
    "                    break\n",
    "                else: #backoff\n",
    "                    ngram = ngram[1:]\n",
    "            if len(ngram)==0:\n",
    "                lm_state = ()\n",
    "            old_lm_state = lm_state\n",
    "        # if this is a previously fixed character and influenced by the newly-fixed character\n",
    "        # substract the old score and add the new score to the previous score.\n",
    "        elif (char in mapping.keys()) and (triggerChangeFlag>0):\n",
    "            token = mapping[char]\n",
    "            old_lm_state, old_logprob = lm.score(old_lm_state, token)\n",
    "            new_score -= old_logprob\n",
    "            lm_state, logprob = lm.score(lm_state, token)\n",
    "            new_score += logprob\n",
    "            triggerChangeFlag -= 1\n",
    "        # if this is a newly-fixed charater, simply add the new score to the previous score\n",
    "        elif char == new_f:\n",
    "            (lm_state, logprob) = lm.score(lm_state, new_e)\n",
    "            new_score += logprob\n",
    "            triggerChangeFlag = 5\n",
    "            old_lm_state = ()\n",
    "        # if this is a unknown character, there is no influence on the previous score\n",
    "        else:\n",
    "            lm_state = ()\n",
    "            old_lm_state = ()\n",
    "            triggerChangeFlag = 0\n",
    "    # treat the end tag '<\\s>' as previously fixed character\n",
    "    if triggerChangeFlag:\n",
    "        new_score -= lm.end(old_lm_state)\n",
    "        new_score += lm.end(lm_state)\n",
    "    return new_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beam_search we implemented is based on the pseudo code mentioned in the assignment. The main change I made was to use customized ext_limit for each plaintext character instead of a general value. The details can be found in the following notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(cipher, ext_order, score_func, ext_limits, topn=1):\n",
    "    '''\n",
    "    finds the mappings between cipher char and plaintext char, returns the mapping dictionary\n",
    "    ext_order -- list, the unigram char list sorted by their count DESC\n",
    "    ext_limits -- int, defines maximum number of cipher char can be mapped to a plaintext char\n",
    "    topn -- int, defines the number of dictionaries we want to keep while pruning\n",
    "    '''\n",
    "    print('Number of unique symbols in cipher:', len(ext_order))\n",
    "    # mapping relationships already found with score\n",
    "    Hs = [(defaultdict(dict), 0)]\n",
    "    # hypothesis mapping relationships with score\n",
    "    Ht = []\n",
    "    # initialize the cardinality (number of unique cipher text)\n",
    "    cardinality = 0\n",
    "    # list of plaintext characters\n",
    "    Ve = [chr(i) for i in range(97, 123, 1)]\n",
    "    while cardinality < len(ext_order):\n",
    "        f = ext_order[cardinality]\n",
    "        print('Working on symbol: ', f, f'({cardinality+1})')\n",
    "        for phi, previous_score in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = copy.deepcopy(phi)\n",
    "                new_map = {f: e}\n",
    "                phi_prime.update(new_map)\n",
    "                counts = len([v for k, v in phi_prime.items() if v == e])\n",
    "                ext_limit = ext_limits[e]\n",
    "                if counts <= ext_limit:\n",
    "                    Ht.append((phi_prime, score_func(cipher, phi, f, e, previous_score)))\n",
    "        # prune the histogram\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]\n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "        #print('Current score: ', Hs[0][1], 'Worst score: ', Hs[min(len(Hs)-1, topn-1)][1])\n",
    "        #print(Hs)\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deciphering the Zodiac Killer cipher, test the algorithm with some simple test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first test case is a simple one to one mapping. <br>\n",
    "Plaintext: `defendtheeastwallofthecastle` <br>\n",
    "Cipher: `giuifgceiiprctpnnduceiqprcni` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique symbols in cipher: 14\n",
      "Working on symbol:  A (1)\n",
      "Working on symbol:  O (2)\n",
      "Working on symbol:  Z (3)\n",
      "Working on symbol:  V (4)\n",
      "Working on symbol:  R (5)\n",
      "Working on symbol:  B (6)\n",
      "Working on symbol:  K (7)\n",
      "Working on symbol:  L (8)\n",
      "Working on symbol:  Q (9)\n",
      "Working on symbol:  U (10)\n",
      "Working on symbol:  F (11)\n",
      "Working on symbol:  P (12)\n",
      "Working on symbol:  I (13)\n",
      "Working on symbol:  S (14)\n",
      "Deciphered result:  queenforcementedbycoveted\n"
     ]
    }
   ],
   "source": [
    "one_to_one_cipher = 'SIAAZQLKBAVAZOARFPBLUAOAR'\n",
    "one_to_one_cipher_desc = get_statistics(one_to_one_cipher, cipher=True)\n",
    "one_to_one_ext_order = find_ext_order(one_to_one_cipher_desc)[0][0]\n",
    "one_to_one_ext_limits = dict()\n",
    "for e in [chr(i) for i in range(97, 123, 1)]:\n",
    "    one_to_one_ext_limits[e] = 1\n",
    "one_to_one_mappings = beam_search(one_to_one_cipher_desc['content'], one_to_one_ext_order,\\\n",
    "                                  score, one_to_one_ext_limits, 5000)\n",
    "one_to_one_mapping = one_to_one_mappings[0][0]\n",
    "one_to_one_decipher_text = ''\n",
    "for char in one_to_one_cipher_desc['content']:\n",
    "    one_to_one_decipher_text += one_to_one_mapping[char]\n",
    "print('Deciphered result: ', one_to_one_decipher_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_fn(Ve, phi, f, cipher, previous_score, ext_limits):\n",
    "    ret = []\n",
    "    for e in Ve:\n",
    "        phi_prime = copy.deepcopy(phi)\n",
    "        new_map = {f: e}\n",
    "        phi_prime.update(new_map)\n",
    "        counts = len([v for k, v in phi_prime.items() if v == e])\n",
    "        if counts <= ext_limits[e]:\n",
    "            ret.append((phi_prime, score(cipher, phi, f, e, previous_score)))\n",
    "    return ret\n",
    "\n",
    "def beam_search_mp(cipher, ext_order, ext_limits, topn=1):\n",
    "\n",
    "    # initialization\n",
    "    Hs = [(defaultdict(dict), 0)]\n",
    "    Ht = []\n",
    "    cardinality = 0\n",
    "    Ve = [chr(i) for i in range(97, 123, 1)]\n",
    "    \n",
    "    while cardinality < len(ext_order):\n",
    "        f = ext_order[cardinality]\n",
    "        print('Working on symbol: ', f, f'({cardinality+1})')\n",
    "        \n",
    "        mainStart = time.time()\n",
    "        result = []\n",
    "        p = Pool(cpu_count())\n",
    "             \n",
    "        for phi, previous_score in Hs: \n",
    "            result.append(p.apply_async(parallel_fn, args=(Ve, phi, f, cipher, previous_score, ext_limits))) \n",
    "                            \n",
    "        p.close() \n",
    "        p.join()  \n",
    "\n",
    "        Ht = []\n",
    "        for subp in result:\n",
    "            Ht += subp.get()\n",
    "    \n",
    "        # prune the histogram\n",
    "        mainEnd = time.time()\n",
    "        print ('Running Time for this symbol: %0.2f seconds.' % (mainEnd-mainStart))\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]    \n",
    "        \n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "        print('Current score: ', Hs[0][1])\n",
    "        \n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decipher Zodiac Killer cipher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, we use different ext_limit for different plaintext symbol. We use the following `ext_limits` to limit the ext_order. The goal is to customize the `ext_limit` for each plaintext character so that more symbols can be mapped to the more frequent plaintext character. The `ext_limit` is calculated by multiplying the relative frequency of the paintext character in wiki text by the number of unique cipher symbols. We believe this can dramatically improve the running time since the required amount of computation in each iteration is minimized. We use the ceiling instead of floor to ensure the `ext_limit` is large enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 5, 'b': 1, 'c': 2, 'd': 3, 'e': 7, 'f': 2, 'g': 2, 'h': 3, 'i': 4, 'j': 1, 'k': 1, 'l': 3, 'm': 2, 'n': 4, 'o': 4, 'p': 2, 'q': 1, 'r': 4, 's': 4, 't': 5, 'u': 2, 'v': 1, 'w': 1, 'x': 1, 'y': 1, 'z': 1}\n"
     ]
    }
   ],
   "source": [
    "ext_limits = dict()\n",
    "for e in [chr(i) for i in range(97, 123, 1)]:\n",
    "    ext_limits[e] = math.ceil(plaintxt_desc['relative_freq'][e]*cipher_desc['vocab_length']/100)\n",
    "print(ext_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ext_order = candidate_orders[4]\n",
    "# mappings = beam_search(cipher_desc['content'], ext_order, score, ext_limits, 100000)\n",
    "# mapping = mappings[0][0]\n",
    "# decipher_text = ''\n",
    "# for char in cipher_desc['content']:\n",
    "#     decipher_text += mapping[char]\n",
    "# print(decipher_text)\n",
    "# #print('score', lm.score_seq(decipher_text))\n",
    "# print(symbol_error_rate(decipher_text, 'data/_ref_Zodiac_408.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = None\n",
    "for ext_order in candidate_orders:\n",
    "    mappings = beam_search_mp(cipher_desc['content'], ext_order, ext_limits, 100000)\n",
    "    mapping = mappings[0][0]\n",
    "    decipher_text = ''\n",
    "    for char in cipher_desc['content']:\n",
    "        decipher_text += mapping[char]\n",
    "    if best_score is None:\n",
    "        best_order = ext_order\n",
    "        best_score = lm.score_seq(decipher_text)\n",
    "    elif lm.score_seq(decipher_text) > best_score:\n",
    "        best_score = lm.score_seq(decipher_text)\n",
    "        best_order = ext_order\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on symbol:  P (1)\n",
      "Running Time for this symbol: 0.22 seconds.\n",
      "Current score:  -12.616786199999998\n",
      "Working on symbol:  B (2)\n",
      "Running Time for this symbol: 0.23 seconds.\n",
      "Current score:  -25.280227800000016\n",
      "Working on symbol:  ∑ (3)\n",
      "Running Time for this symbol: 0.72 seconds.\n",
      "Current score:  -32.58730020000001\n",
      "Working on symbol:  º (4)\n",
      "Running Time for this symbol: 14.46 seconds.\n",
      "Current score:  -45.77077729999998\n",
      "Working on symbol:  ∫ (5)\n",
      "Running Time for this symbol: 85.84 seconds.\n",
      "Current score:  -58.652923079999994\n",
      "Working on symbol:  A (6)\n",
      "Running Time for this symbol: 106.47 seconds.\n",
      "Current score:  -67.97915410000006\n",
      "Working on symbol:  O (7)\n",
      "Running Time for this symbol: 92.25 seconds.\n",
      "Current score:  -75.05363730000006\n",
      "Working on symbol:  R (8)\n",
      "Running Time for this symbol: 93.32 seconds.\n",
      "Current score:  -86.39289188000002\n",
      "Working on symbol:  u (9)\n",
      "Running Time for this symbol: 96.67 seconds.\n",
      "Current score:  -95.91491228000005\n",
      "Working on symbol:  À (10)\n",
      "Running Time for this symbol: 100.62 seconds.\n",
      "Current score:  -103.40856350000006\n",
      "Working on symbol:  / (11)\n",
      "Running Time for this symbol: 108.13 seconds.\n",
      "Current score:  -110.53825624000002\n",
      "Working on symbol:  Z (12)\n",
      "Running Time for this symbol: 104.98 seconds.\n",
      "Current score:  -118.65075089000004\n",
      "Working on symbol:  ∆ (13)\n",
      "Running Time for this symbol: 105.13 seconds.\n",
      "Current score:  -121.16935812000004\n",
      "Working on symbol:  V (14)\n",
      "Running Time for this symbol: 103.63 seconds.\n",
      "Current score:  -129.72932193000008\n",
      "Working on symbol:  – (15)\n",
      "Running Time for this symbol: 109.12 seconds.\n",
      "Current score:  -135.98298503000007\n",
      "Working on symbol:  W (16)\n",
      "Running Time for this symbol: 108.55 seconds.\n",
      "Current score:  -145.7364638599999\n",
      "Working on symbol:  √ (17)\n",
      "Running Time for this symbol: 112.73 seconds.\n",
      "Current score:  -152.34066253000006\n",
      "Working on symbol:  I (18)\n",
      "Running Time for this symbol: 115.00 seconds.\n",
      "Current score:  -163.37520854000013\n",
      "Working on symbol:  • (19)\n",
      "Running Time for this symbol: 118.13 seconds.\n",
      "Current score:  -171.40069213\n",
      "Working on symbol:  X (20)\n",
      "Running Time for this symbol: 119.44 seconds.\n",
      "Current score:  -180.8282954299999\n",
      "Working on symbol:  ≈ (21)\n",
      "Running Time for this symbol: 117.24 seconds.\n",
      "Current score:  -189.8510866699999\n",
      "Working on symbol:  — (22)\n",
      "Running Time for this symbol: 142.64 seconds.\n",
      "Current score:  -205.3758945699998\n",
      "Working on symbol:  π (23)\n",
      "Running Time for this symbol: 126.78 seconds.\n",
      "Current score:  -212.36930816999978\n",
      "Working on symbol:  + (24)\n",
      "Running Time for this symbol: 126.82 seconds.\n",
      "Current score:  -223.18535779999976\n",
      "Working on symbol:  µ (25)\n",
      "Running Time for this symbol: 129.27 seconds.\n",
      "Current score:  -232.35764757999993\n",
      "Working on symbol:  ∞ (26)\n",
      "Running Time for this symbol: 130.87 seconds.\n",
      "Current score:  -241.03217423\n",
      "Working on symbol:  E (27)\n",
      "Running Time for this symbol: 130.13 seconds.\n",
      "Current score:  -251.67131583\n",
      "Working on symbol:  H (28)\n",
      "Running Time for this symbol: 134.47 seconds.\n",
      "Current score:  -261.07970474699994\n",
      "Working on symbol:  F (29)\n",
      "Running Time for this symbol: 141.16 seconds.\n",
      "Current score:  -268.97488966999987\n",
      "Working on symbol:  “ (30)\n",
      "Running Time for this symbol: 136.85 seconds.\n",
      "Current score:  -277.7050109300002\n",
      "Working on symbol:  Q (31)\n",
      "Running Time for this symbol: 137.66 seconds.\n",
      "Current score:  -283.76201174700014\n",
      "Working on symbol:  G (32)\n",
      "Running Time for this symbol: 137.49 seconds.\n",
      "Current score:  -293.2395206300002\n",
      "Working on symbol:  y (33)\n",
      "Running Time for this symbol: 143.25 seconds.\n",
      "Current score:  -305.1749985590002\n",
      "Working on symbol:  æ (34)\n",
      "Running Time for this symbol: 145.30 seconds.\n",
      "Current score:  -316.8552705900003\n",
      "Working on symbol:  K (35)\n",
      "Running Time for this symbol: 156.04 seconds.\n",
      "Current score:  -325.20538628999986\n",
      "Working on symbol:  D (36)\n",
      "Running Time for this symbol: 136.92 seconds.\n",
      "Current score:  -332.6773203540003\n",
      "Working on symbol:  £ (37)\n",
      "Running Time for this symbol: 140.33 seconds.\n",
      "Current score:  -345.9185818739994\n",
      "Working on symbol:  M (38)\n",
      "Running Time for this symbol: 142.47 seconds.\n",
      "Current score:  -356.11914444699994\n",
      "Working on symbol:  Ç (39)\n",
      "Running Time for this symbol: 140.34 seconds.\n",
      "Current score:  -363.0117318299999\n",
      "Working on symbol:  J (40)\n",
      "Running Time for this symbol: 143.22 seconds.\n",
      "Current score:  -375.473122367\n",
      "Working on symbol:  ∏ (41)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mappings = beam_search_mp(cipher_desc['content'], best_order, ext_limits, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = mappings[0][0]\n",
    "decipher_text = ''\n",
    "for char in cipher_desc['content']:\n",
    "    decipher_text += mapping[char]\n",
    "print(decipher_text)\n",
    "#print('score', lm.score_seq(decipher_text))\n",
    "#print(symbol_error_rate(decipher_text, 'data/_ref_Zodiac_408.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

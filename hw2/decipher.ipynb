{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Decipherment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Our main efforts to improve the baseline:\n",
    "- Implement find_ext_order function to find better extension order. \n",
    "- Rewrite the score function which is used in beam_search function. 3-4 x faster. \n",
    "- Multiprocessing. 10 x faster with 64 core VM compared to single core implementation.\n",
    "- Customize the ext_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Contents  <a id='part-0'>\n",
    "-------------------\n",
    "- [Part 1: Load the libraries](#part-1)\n",
    "- [Part 2: Code from the default notebook](#part-2)\n",
    "- [Part 3: Implementation for Reference 3 to find the optimal extension order](#part-3)\n",
    "- [Part 4: Baseline with better extension order and faster score function](#part-4)\n",
    "- [Part 5: Test case](#part-5)\n",
    "- [Part 6: Multi-processing](#part-6)\n",
    "- [Part 7: Decipher Zodiac Killer cipher](#part-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Part 1. Load the libraries <a id='part-1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import defaultdict, Counter\n",
    "import collections\n",
    "import pprint\n",
    "import math\n",
    "import bz2\n",
    "from ngram import *\n",
    "import sys, string, os\n",
    "import copy\n",
    "import pickle\n",
    "#from joblib import Parallel, delayed\n",
    "import itertools\n",
    "from multiprocessing import Process,Pool, cpu_count\n",
    "import datetime, time, random\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  [Back to contents](#part-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Part 2. Code from the default notebook <a id='part-2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First let us read in the cipher text from the `data` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    if filename[-4:] == \".bz2\":\n",
    "        with bz2.open(filename, 'rt', encoding='utf-8-sig') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename, 'r', encoding='utf-8-sig') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    return content\n",
    "\n",
    "cipher = read_file(\"data/cipher.txt\")\n",
    "# print(cipher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "While using `get_statistics`, make sure that `cipher=True` is set when the input is a ciphertext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_statistics(content, cipher=True):\n",
    "    stats = {}\n",
    "    content = list(content)\n",
    "    split_content = [x for x in content if x != '\\n' and x!=' ']\n",
    "    length = len(split_content)\n",
    "    symbols = set(split_content)\n",
    "    uniq_sym = len(list(symbols))\n",
    "    freq = collections.Counter(split_content)\n",
    "    rel_freq = {}\n",
    "    for sym, frequency in freq.items():\n",
    "        rel_freq[sym] = (frequency/length)*100\n",
    "        \n",
    "    if cipher:\n",
    "        stats = {'content':split_content, 'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    else:\n",
    "        stats = {'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cipher_desc = get_statistics(cipher, cipher=True)\n",
    "plaintxt = read_file(\"data/default.wiki.txt.bz2\")\n",
    "plaintxt_desc = get_statistics(plaintxt, cipher=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.5 s, sys: 971 ms, total: 25.5 s\n",
      "Wall time: 25.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequence = 'In a few cases, a multilingual artifact has been necessary to facilitate decipherment, the Rosetta Stone being the classic example. Statistical techniques provide another pathway to decipherment, as does the analysis of modern languages derived from ancient languages in which undeciphered texts are written. Archaeological and historical information is helpful in verifying hypothesized decipherments.'\n",
    "\n",
    "# lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=True)\n",
    "lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  [Back to contents](#part-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Implementation for Reference 3 to find the optimal extension order <a id='part-3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the implementation of the reference 'Improved Decipherment of Homophonic Ciphers'. The goal is to find the best extension order. As the paper mentioned, it is important to find a better optimal extension order which is helpful to improve both the speed and accuracy. If the correct answer has been pruned out at a very early stage, it is not quite possible that the text can be fully deciphered since the following score is computed based on a wrong partial deciphered text. With beam size of 10000, we experimented with several sets of extension orders. With the help of ground truth, we are able to monitor when the correct answer has been pruned. If we follow the frequency order of those symbols, the correct answer can be pruned as early as the fourth or fifth iteration. Finally, I chose the weights \\[1,1,1,1,2,3\\] suggested by Anoop in a discussion post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate the sharp_n for the specified n-gram order\n",
    "def find_sharp_n(cipher_desc, symbols_found, n_order):\n",
    "    '''\n",
    "    finds the #n for order n_order\n",
    "    cipher_desc -- cipher statistics\n",
    "    symbols_found -- list of single character string,\n",
    "                     specifies the list of symbols have been placed in the extention order\n",
    "    n_order -- int, specifies the order of n-gram\n",
    "    '''\n",
    "    sharp_n = 0\n",
    "    for i in range(len(cipher_desc['content'])-n_order+1):\n",
    "        for j in range(i, i+n_order, 1):\n",
    "            if cipher_desc['content'][j] not in symbols_found:\n",
    "                break\n",
    "            if j == (i+n_order-1):\n",
    "                sharp_n += 1\n",
    "                #print(cipher_desc['content'][i:i+n_order])\n",
    "    return sharp_n            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a beam search to find the optimal extension order. The code below is pretty similar to the beam_search function. Most of the code is copied from it. For simplicity, the variable name might not quite make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ext_order(cipher_desc, topn=100, weights=[1,1,1,1,2,3]):\n",
    "    '''\n",
    "    finds the best order of deciphering cipher symbols (find best extention order)\n",
    "    cipher_desc -- cipher statistics\n",
    "    topn -- int, number of best trees we want to keep during iteration, aka beam size\n",
    "    weights -- list of int, weight for #n, n varies from 1 to 6 in the case of 6 gram\n",
    "    '''\n",
    "    # symbols already found with score\n",
    "    Hs = [([], 0)]\n",
    "    # hypothesis extended symbols with score\n",
    "    Ht = []\n",
    "    # initialize the cardinality (number of unique cipher text)\n",
    "    cardinality = 0\n",
    "    # if no weight is specified for unigram, use the most frequent symbol as the starting point\n",
    "    if weights[0] == 0:\n",
    "        cardinality += 1\n",
    "        Hs.append(([sorted(cipher_desc['frequencies'], key=cipher_desc['frequencies'].get, reverse=True)[0]], 0))\n",
    "    # list of cipher symbols\n",
    "    Ve = sorted(cipher_desc['frequencies'], key=cipher_desc['frequencies'].get, reverse=True)\n",
    "    while cardinality < cipher_desc['vocab_length']:\n",
    "        for phi, previous_score in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = copy.deepcopy(phi)\n",
    "                if e in phi_prime:\n",
    "                    continue\n",
    "                else:\n",
    "                    phi_prime.append(e)\n",
    "                    this_score = 0\n",
    "                    for i in range(len(weights)):\n",
    "                        this_score += weights[i]*find_sharp_n(cipher_desc, phi_prime, i+1)\n",
    "                    Ht.append((phi_prime, this_score))\n",
    "        # prune the histogram\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]                    \n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may takes a while (3.5 min on my machine)\n",
    "ext_orders = find_ext_order(cipher_desc, topn=100, weights=[1,1,1,1,2,3])\n",
    "ext_order = ext_orders[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [Back to contents](#part-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Baseline with better extension order and faster score function <a id='part-4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first change I made to the baseline was to rewrite the score function to optimize the running speed. The change I made is to score the newly fixed symbol plantext character pair and corresponding influenced previously fixed plantext character based on the previous score instead of scoring the whole bitstring in each iteration. For instance, 'oooo...o' -> 'oooo..xo'. The new score can be calculated by adding unigram score of 'x' to the previous score, substracting unigram score of 'o' following 'x' and bigram score of '<\\s>' from the previous score, and adding bigram score of 'o' following 'x' and trigram score of '<\\s>' to the previous score. With this approach, the running time was improved to 20 minitues from more than one hour with a beamsize of 10000 on my machine with i7 7700k cpu. And the computed score is almost same as the score computed with score_bit_string function (the difference is within 0.00000000001). Another approach to speed up the whole process we tried is multiprocessing. We will talk about that in details in the following notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(cipher, phi, new_f, new_e, previous_score):\n",
    "    '''\n",
    "    scores the phi_prime based on the previous score, returns a float\n",
    "    cipher -- list of single character string\n",
    "    phi -- dictionary, old mapping e->[f]\n",
    "    new_f -- single-character string, extended symbol\n",
    "    previous_score -- float, old score for phi\n",
    "    '''\n",
    "    mapping = phi\n",
    "    new_score = previous_score\n",
    "    # for the first iteration, the previous score should be -2.545382 instead of 0\n",
    "    # this is because the score of an empty string is not 0 whiling scoring with bitstring\n",
    "    # the value can be obtained by calling lm.score_bitstring('thisisatest', '...........')\n",
    "    if len(phi)==0:\n",
    "        new_score += -2.545382\n",
    "    lm_state = lm.begin()\n",
    "    old_lm_state = lm.begin()\n",
    "    # this Flag is used to track if a newly-fixed character affects the previously-fixed character\n",
    "    triggerChangeFlag = 0\n",
    "    for i in range(len(cipher)):\n",
    "        char = cipher[i]\n",
    "        # if this is a previously fixed character and not influenced by the newly-fixed character\n",
    "        # we only need to track the lm_state and old lm_state, no need to compute the score\n",
    "        if (char in mapping.keys()) and (triggerChangeFlag==0):\n",
    "            token = mapping[char]\n",
    "            ngram = lm_state + (token,)\n",
    "            while len(ngram)> 0:\n",
    "                if ngram in lm.table:\n",
    "                    lm_state = ngram[-lm.history:]\n",
    "                    break\n",
    "                else: #backoff\n",
    "                    ngram = ngram[1:]\n",
    "            if len(ngram)==0:\n",
    "                lm_state = ()\n",
    "            old_lm_state = lm_state\n",
    "        # if this is a previously fixed character and influenced by the newly-fixed character\n",
    "        # substract the old score and add the new score to the previous score.\n",
    "        elif (char in mapping.keys()) and (triggerChangeFlag>0):\n",
    "            token = mapping[char]\n",
    "            old_lm_state, old_logprob = lm.score(old_lm_state, token)\n",
    "            new_score -= old_logprob\n",
    "            lm_state, logprob = lm.score(lm_state, token)\n",
    "            new_score += logprob\n",
    "            triggerChangeFlag -= 1\n",
    "        # if this is a newly-fixed charater, simply add the new score to the previous score\n",
    "        elif char == new_f:\n",
    "            (lm_state, logprob) = lm.score(lm_state, new_e)\n",
    "            new_score += logprob\n",
    "            triggerChangeFlag = 5\n",
    "            old_lm_state = ()\n",
    "        # if this is a unknown character, there is no influence on the previous score\n",
    "        else:\n",
    "            lm_state = ()\n",
    "            old_lm_state = ()\n",
    "            triggerChangeFlag = 0\n",
    "    # treat the end tag '<\\s>' as previously fixed character\n",
    "    if triggerChangeFlag:\n",
    "        new_score -= lm.end(old_lm_state)\n",
    "        new_score += lm.end(lm_state)\n",
    "    return new_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beam_search we implemented is based on the pseudo code mentioned in the assignment. The main change I made was to use customized ext_limit for each plaintext character instead of a general value. The details can be found in the following notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(cipher, ext_order, ext_limits, topn=1):\n",
    "    '''\n",
    "    finds the mappings between cipher char and plaintext char, returns the mapping dictionary\n",
    "    ext_order -- list, the unigram char list sorted by their count DESC\n",
    "    ext_limits -- int, defines maximum number of cipher char can be mapped to a plaintext char\n",
    "    topn -- int, defines the number of dictionaries we want to keep while pruning\n",
    "    '''\n",
    "    print('Number of unique symbols in cipher:', len(ext_order))\n",
    "    # mapping relationships already found with score\n",
    "    Hs = [(defaultdict(dict), 0)]\n",
    "    # hypothesis mapping relationships with score\n",
    "    Ht = []\n",
    "    # initialize the cardinality (number of unique cipher text)\n",
    "    cardinality = 0\n",
    "    # list of plaintext characters\n",
    "    Ve = [chr(i) for i in range(97, 123, 1)]\n",
    "    while cardinality < len(ext_order):\n",
    "        f = ext_order[cardinality]\n",
    "        print('Working on symbol: ', f, '(%s)' % (cardinality+1))\n",
    "        for phi, previous_score in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = copy.deepcopy(phi)\n",
    "                new_map = {f: e}\n",
    "                phi_prime.update(new_map)\n",
    "                counts = len([v for k, v in phi_prime.items() if v == e])\n",
    "                ext_limit = ext_limits[e]\n",
    "                if counts <= ext_limit:\n",
    "                    Ht.append((phi_prime, score(cipher, phi, f, e, previous_score)))\n",
    "        # prune the histogram\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]\n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "        #print('Current score: ', Hs[0][1], 'Worst score: ', Hs[min(len(Hs)-1, topn-1)][1])\n",
    "        #print(Hs)\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [Back to contents](#part-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Test case <a id='part-5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deciphering the Zodiac Killer cipher, test the algorithm with a simple one to one mapping test case <br>\n",
    "Plaintext: `defendtheeastwallofthecastle` <br>\n",
    "Cipher: `giuifgceiiprctpnnduceiqprcni` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique symbols in cipher: 12\n",
      "Working on symbol:  i (1)\n",
      "Working on symbol:  p (2)\n",
      "Working on symbol:  r (3)\n",
      "Working on symbol:  c (4)\n",
      "Working on symbol:  t (5)\n",
      "Working on symbol:  n (6)\n",
      "Working on symbol:  e (7)\n",
      "Working on symbol:  q (8)\n",
      "Working on symbol:  u (9)\n",
      "Working on symbol:  d (10)\n",
      "Working on symbol:  g (11)\n",
      "Working on symbol:  f (12)\n",
      "Deciphered result:  defendtheeastwallofthecastle\n"
     ]
    }
   ],
   "source": [
    "one_to_one_cipher = 'giuifgceiiprctpnnduceiqprcni'\n",
    "one_to_one_cipher_desc = get_statistics(one_to_one_cipher, cipher=True)\n",
    "one_to_one_ext_order = find_ext_order(one_to_one_cipher_desc)[0][0]\n",
    "one_to_one_ext_limits = dict()\n",
    "for e in [chr(i) for i in range(97, 123, 1)]:\n",
    "    one_to_one_ext_limits[e] = 1\n",
    "one_to_one_mappings = beam_search(one_to_one_cipher_desc['content'], one_to_one_ext_order,\\\n",
    "                                  one_to_one_ext_limits, 500)\n",
    "one_to_one_mapping = one_to_one_mappings[0][0]\n",
    "one_to_one_decipher_text = ''\n",
    "for char in one_to_one_cipher_desc['content']:\n",
    "    one_to_one_decipher_text += one_to_one_mapping[char]\n",
    "print('Deciphered result: ', one_to_one_decipher_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't come up with a homophobic cipher. The reason is that our algorithm is able to decipher the Zodiac with a beamsize of 10000 after fixing three ground true mapping relationships (result not shown). The symbol error rate for that is ~5%. With a beamsize of 10000, the algorithm cannot correctly decipher the text all by its own. But it is enough to prove the baseline algorithm works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [Back to contents](#part-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Part 6. Multi-processing <a id='part-6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To furthur improve the running speed, we tried multiprocessing. <br>\n",
    "**NOTE: This multi-processing version only works for linux or MAC operating system. It doesn't work for Windows system. Please run beam_search function instead of beam_search_mp if you are using a Windows machine.** <br>\n",
    "This multi-processing implementation makes experimenting with beam size of 1M possible. With a 64 core linux instance, we are able to finish the whole process with 6h 30min. Compared to the running time mentioned in the original 2013 Nuhn paper, our implementation is faster than theirs (if we ignore the difference in the CPUs). They were using 128 core machine and the whole process takes more than 5 hours. <br>\n",
    "Note that this multi-processing implementation is also memory-hungry. With 2M beamsize, the RAM must be larger than 256G for 128 core machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def parallel_fn(Ve, phi, f, cipher, previous_score, ext_limits):\n",
    "    ret = []\n",
    "    for e in Ve:\n",
    "        phi_prime = copy.deepcopy(phi)\n",
    "        new_map = {f: e}\n",
    "        phi_prime.update(new_map)\n",
    "        counts = len([v for k, v in phi_prime.items() if v == e])\n",
    "        if counts <= ext_limits[e]:\n",
    "            ret.append((phi_prime, score(cipher, phi, f, e, previous_score)))\n",
    "    return ret\n",
    "\n",
    "def beam_search_mp(cipher, ext_order, ext_limits, topn=1):\n",
    "\n",
    "    # initialization\n",
    "    Hs = [(defaultdict(dict), 0)]\n",
    "    Ht = []\n",
    "    cardinality = 0\n",
    "    Ve = [chr(i) for i in range(97, 123, 1)]\n",
    "    \n",
    "    while cardinality < len(ext_order):\n",
    "        f = ext_order[cardinality]\n",
    "        print('Working on symbol: ', f, '(%s)' % (cardinality+1))\n",
    "        \n",
    "        mainStart = time.time()\n",
    "        result = []\n",
    "        p = Pool(cpu_count())\n",
    "             \n",
    "        for phi, previous_score in Hs: \n",
    "            result.append(p.apply_async(parallel_fn, args=(Ve, phi, f, cipher, previous_score, ext_limits))) \n",
    "                            \n",
    "        p.close() \n",
    "        p.join()  \n",
    "\n",
    "        Ht = []\n",
    "        for subp in result:\n",
    "            Ht += subp.get()\n",
    "            \n",
    "        if cardinality < 10 or cardinality >= 40:\n",
    "            topn = 100000\n",
    "        else:\n",
    "            topn = 1000000\n",
    "    \n",
    "        # prune the histogram\n",
    "        mainEnd = time.time()\n",
    "        print ('Running Time for this symbol: %0.2f seconds.' % (mainEnd-mainStart))\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]    \n",
    "        \n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()        \n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  [Back to contents](#part-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7. Decipher Zodiac Killer cipher <a id='part-7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As briefly mentioned above, we use different ext_limit for different plaintext symbol. We use the following `ext_limits` to limit the ext_order. The goal is to customize the `ext_limit` for each plaintext character so that more symbols can be mapped to the more frequent plaintext character. The `ext_limit` is calculated by multiplying the relative frequency of the paintext character in wiki text by the number of unique cipher symbols. We believe this can dramatically improve the running time since the required amount of computation in each iteration is minimized. We use the ceiling instead of floor to ensure the `ext_limit` is large enough. We also add one to each ext_limit so that we can still be able to get close to the correct answer. For instance, the limit for 'e' is 7 in the case of Zodiac Killer task. If the correct answer was pruned and 'e' has been used up, the algorithm will make it worse. if the correct answer was pruned. Of course this approach might not be perfect if less frequent plaintext character is mapped to more cipher symbols. But even that is the case, the error rate should not increase significantly since the frequency of those less frequent plaintext should not be large (if the character distribution of the plaintext in the cipher task is similar to that of the one used to train the language model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g': 2, 'c': 2, 'q': 1, 'o': 4, 'b': 1, 'a': 5, 'v': 1, 'm': 2, 's': 4, 'u': 2, 'e': 7, 'f': 2, 'k': 1, 'r': 4, 'x': 1, 'h': 3, 'j': 1, 't': 5, 'i': 4, 'l': 3, 'n': 4, 'y': 1, 'd': 3, 'w': 1, 'z': 1, 'p': 2}\n"
     ]
    }
   ],
   "source": [
    "ext_limits = dict()\n",
    "for e in [chr(i) for i in range(97, 123, 1)]:\n",
    "    ext_limits[e] = math.ceil(plaintxt_desc['relative_freq'][e]*cipher_desc['vocab_length']/100)+1\n",
    "print(ext_limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to our improvement on the score function and the multiprocessing implementation, we are able to try larger beam size. We made several attempts. Here is the result. <br>\n",
    "**64 vCPU VM on AZURE** Beam size: 1M; Running time: 6h 30min; Symbol error rate: 0.694; The correct leaf was pruned at iteration 13. <br>\n",
    "**96 vCPU VM on AWS** Beam size: 1M for the first 10 iterations, 2M for the next 30 iterations, 1M afterwards; Running time: 5h 55min; Symbol error rate: 0.546; The correct leaf was pruned at iteration 15. <br>\n",
    "We believe that if we have enough time and computation resources we would be able to find the final answer. But for now, the best we can achieve is 0.546. <br>\n",
    "With SER of 0.546, the text starts to make sense. After the first run, we didn't freeze some mappings which might look correct. If we do so and make a another run, I am pretty sure we can find the closer decipher based on the fact the we can achieve SER of 0.05 after freezing three mappings. The reason we didn't do that is because that is some sort of cheating. Although the sentences start to make sense, we still cannot make sure that is the correct mapping without knowing the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant_ext_limit = 4\n",
    "# ext_limits = {}\n",
    "# for e in [chr(i) for i in range(97, 123, 1)]:\n",
    "#     ext_limits[e] = constant_ext_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on symbol:  E (1)\n",
      "Running Time for this symbol: 2.53 seconds.\n",
      "Best score:  -10.7856218 Worst score:  -29.749483999999995\n",
      "gold score -10.785621800000001\n",
      "Working on symbol:  ∑ (2)\n",
      "Running Time for this symbol: 2.65 seconds.\n",
      "Best score:  -20.517739599999995 Worst score:  -59.14061499999999\n",
      "gold score -24.181161000000003\n",
      "Working on symbol:  B (3)\n",
      "Running Time for this symbol: 2.63 seconds.\n",
      "Best score:  -32.11996419999999 Worst score:  -100.08261399999998\n",
      "gold score -38.09201220000001\n",
      "Working on symbol:  P (4)\n",
      "Running Time for this symbol: 5.16 seconds.\n",
      "Best score:  -40.82754000000006 Worst score:  -133.53752555999998\n",
      "gold score -48.728844000000024\n",
      "Working on symbol:  º (5)\n",
      "Running Time for this symbol: 63.11 seconds.\n",
      "Best score:  -54.011017099999975 Worst score:  -81.53140200000003\n",
      "gold score -62.340047100000035\n",
      "Working on symbol:  ∫ (6)\n",
      "Running Time for this symbol: 161.73 seconds.\n",
      "Best score:  -66.89316288000005 Worst score:  -85.72715639999998\n",
      "gold score -74.86408880000002\n",
      "Working on symbol:  / (7)\n",
      "Running Time for this symbol: 186.90 seconds.\n",
      "Best score:  -72.68006079000003 Worst score:  -88.17482240000001\n",
      "gold score -82.52081120000001\n",
      "Working on symbol:  Z (8)\n",
      "Running Time for this symbol: 191.65 seconds.\n",
      "Best score:  -81.55473529000004 Worst score:  -94.48621370000002\n",
      "gold score -88.05795994000003\n",
      "Working on symbol:  A (9)\n",
      "Running Time for this symbol: 209.05 seconds.\n",
      "Best score:  -89.06488246800014 Worst score:  -101.2390609099999\n",
      "gold score -98.26804168000001\n",
      "Working on symbol:  ∆ (10)\n",
      "Running Time for this symbol: 227.67 seconds.\n",
      "Best score:  -92.35546822000003 Worst score:  -103.11185669999995\n",
      "gold score -100.32490010000001\n",
      "Working on symbol:  u (11)\n",
      "Running Time for this symbol: 240.82 seconds.\n",
      "Best score:  -102.84589982000004 Worst score:  -113.36156645000005\n",
      "gold score -108.72940661000003\n",
      "Working on symbol:  O (12)\n",
      "Running Time for this symbol: 253.96 seconds.\n",
      "Best score:  -108.45606159000006 Worst score:  -119.62204870000006\n",
      "gold score -114.78476954\n",
      "Working on symbol:  R (13)\n",
      "Running Time for this symbol: 275.19 seconds.\n",
      "Best score:  -122.02985343000013 Worst score:  -133.22469027\n",
      "gold score -131.19456633999997\n",
      "Working on symbol:  À (14)\n",
      "Running Time for this symbol: 266.82 seconds.\n",
      "Best score:  -130.18600501000003 Worst score:  -142.07775613000007\n",
      "gold score -141.07347840999995\n",
      "Working on symbol:  V (15)\n",
      "Running Time for this symbol: 270.86 seconds.\n",
      "Best score:  -138.7204952300001 Worst score:  -151.4654515969999\n",
      "gold score -154.78132610999998\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  – (16)\n",
      "Running Time for this symbol: 480.79 seconds.\n",
      "Best score:  -144.63341993000003 Worst score:  -156.5285812790001\n",
      "gold score -159.95173187299994\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  • (17)\n",
      "Running Time for this symbol: 525.10 seconds.\n",
      "Best score:  -152.04066573000006 Worst score:  -162.8584369600001\n",
      "gold score -171.19284527299996\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  X (18)\n",
      "Running Time for this symbol: 658.83 seconds.\n",
      "Best score:  -162.0370880899999 Worst score:  -172.43172469000004\n",
      "gold score -180.16133218929997\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  W (19)\n",
      "Running Time for this symbol: 696.31 seconds.\n",
      "Best score:  -171.4603068899998 Worst score:  -181.70119339000016\n",
      "gold score -186.21911809217994\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  √ (20)\n",
      "Running Time for this symbol: 627.24 seconds.\n",
      "Best score:  -177.77210604000024 Worst score:  -187.9386414800002\n",
      "gold score -192.58846780217988\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  § (21)\n",
      "Running Time for this symbol: 673.32 seconds.\n",
      "Best score:  -180.27040484000028 Worst score:  -191.18567621999998\n",
      "gold score -199.16802723217987\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  F (22)\n",
      "Running Time for this symbol: 778.70 seconds.\n",
      "Best score:  -187.05565198000033 Worst score:  -197.1628046800002\n",
      "gold score -207.5846719321798\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  H (23)\n",
      "Running Time for this symbol: 804.20 seconds.\n",
      "Best score:  -195.99242198000002 Worst score:  -206.48550829700005\n",
      "gold score -215.20487883217982\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  ≈ (24)\n",
      "Running Time for this symbol: 748.28 seconds.\n",
      "Best score:  -205.07579155999989 Worst score:  -218.10671840999993\n",
      "gold score -226.1684024921798\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  — (25)\n",
      "Running Time for this symbol: 739.27 seconds.\n",
      "Best score:  -222.66583353999977 Worst score:  -235.82344309999996\n",
      "gold score -247.0366185921799\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  π (26)\n",
      "Running Time for this symbol: 838.93 seconds.\n",
      "Best score:  -231.0605547899998 Worst score:  -242.62758108000054\n",
      "gold score -251.37040766117994\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  + (27)\n",
      "Running Time for this symbol: 818.93 seconds.\n",
      "Best score:  -238.8996092999998 Worst score:  -249.92376876999984\n",
      "gold score -255.31671704117988\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  G (28)\n",
      "Running Time for this symbol: 543.35 seconds.\n",
      "Best score:  -246.66369043999973 Worst score:  -258.0454772500002\n",
      "gold score -256.79974044118\n",
      "Working on symbol:  D (29)\n",
      "Running Time for this symbol: 498.52 seconds.\n",
      "Best score:  -255.2839726870003 Worst score:  -265.8208119\n",
      "gold score -260.08657754117996\n",
      "Working on symbol:  K (30)\n",
      "Running Time for this symbol: 420.71 seconds.\n",
      "Best score:  -261.4293211199999 Worst score:  -271.87542650999995\n",
      "gold score -265.08165384117996\n",
      "Working on symbol:  y (31)\n",
      "Running Time for this symbol: 508.42 seconds.\n",
      "Best score:  -271.5749408199999 Worst score:  -284.2733610469995\n",
      "gold score -274.43588344217994\n",
      "Working on symbol:  ∞ (32)\n",
      "Running Time for this symbol: 513.90 seconds.\n",
      "Best score:  -281.46442131999976 Worst score:  -294.3272416400003\n",
      "gold score -279.5501398411801\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  I (33)\n",
      "Running Time for this symbol: 459.40 seconds.\n",
      "Best score:  -298.56585282999964 Worst score:  -310.9194968800005\n",
      "gold score -290.67223916118\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  æ (34)\n",
      "Running Time for this symbol: 444.90 seconds.\n",
      "Best score:  -307.91945474800025 Worst score:  -322.20555542000045\n",
      "gold score -295.5819094611801\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  µ (35)\n",
      "Running Time for this symbol: 420.25 seconds.\n",
      "Best score:  -317.80225592000085 Worst score:  -333.8180130381001\n",
      "gold score -298.9660244811801\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  ∏ (36)\n",
      "Running Time for this symbol: 414.33 seconds.\n",
      "Best score:  -329.3267356450002 Worst score:  -344.49770785799933\n",
      "gold score -316.34484567118005\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  T (37)\n",
      "Running Time for this symbol: 421.47 seconds.\n",
      "Best score:  -338.2655322200007 Worst score:  -355.15590165800035\n",
      "gold score -313.3830230321801\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  ƒ (38)\n",
      "Running Time for this symbol: 455.35 seconds.\n",
      "Best score:  -347.0778854550005 Worst score:  -363.6361929150005\n",
      "gold score -312.85239818598\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  “ (39)\n",
      "Running Time for this symbol: 464.21 seconds.\n",
      "Best score:  -353.3593501110006 Worst score:  -373.1090388749997\n",
      "gold score -319.8460345359799\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  \\ (40)\n",
      "Running Time for this symbol: 399.85 seconds.\n",
      "Best score:  -364.1936498230006 Worst score:  -380.35300745200044\n",
      "gold score -322.6076550359799\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  Q (41)\n",
      "Running Time for this symbol: 426.76 seconds.\n",
      "Best score:  -373.32276415900014 Worst score:  -387.4370032260004\n",
      "gold score -328.8049877959801\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  J (42)\n",
      "Running Time for this symbol: 419.62 seconds.\n",
      "Best score:  -382.21605936 Worst score:  -393.4035285610007\n",
      "gold score -332.31042466842\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  Ç (43)\n",
      "Running Time for this symbol: 148.56 seconds.\n",
      "Best score:  -389.8460957820002 Worst score:  -403.2907524229999\n",
      "gold score -334.6860917784201\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  M (44)\n",
      "Running Time for this symbol: 89.65 seconds.\n",
      "Best score:  -402.72933468199994 Worst score:  -416.1149994510003\n",
      "gold score -337.2555375671201\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  £ (45)\n",
      "Running Time for this symbol: 91.83 seconds.\n",
      "Best score:  -416.0047573712002 Worst score:  -428.6187026650002\n",
      "gold score -348.6672156971198\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  L (46)\n",
      "Running Time for this symbol: 99.74 seconds.\n",
      "Best score:  -424.8830495249998 Worst score:  -442.1967237012004\n",
      "gold score -352.86481681711973\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  ‘ (47)\n",
      "Running Time for this symbol: 100.48 seconds.\n",
      "Best score:  -438.30285461019986 Worst score:  -456.3837953780004\n",
      "gold score -350.5658561171198\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  ^ (48)\n",
      "Running Time for this symbol: 52.57 seconds.\n",
      "Best score:  -452.7671367892 Worst score:  -469.27530175100026\n",
      "gold score -351.3371683371197\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  S (49)\n",
      "Running Time for this symbol: 52.38 seconds.\n",
      "Best score:  -460.7421364089998 Worst score:  -480.36117206000034\n",
      "gold score -348.7287002071197\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  Ã (50)\n",
      "Running Time for this symbol: 51.35 seconds.\n",
      "Best score:  -472.1518742689999 Worst score:  -491.3799139869999\n",
      "gold score -350.6945293971198\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  N (51)\n",
      "Running Time for this symbol: 51.12 seconds.\n",
      "Best score:  -485.6366593040003 Worst score:  -504.7221981040001\n",
      "gold score -356.8109762901198\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  ¢ (52)\n",
      "Running Time for this symbol: 53.15 seconds.\n",
      "Best score:  -491.8206377270002 Worst score:  -515.5889003979999\n",
      "gold score -355.7758263201198\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  Ω (53)\n",
      "Running Time for this symbol: 56.08 seconds.\n",
      "Best score:  -502.3048657600001 Worst score:  -521.3007268360001\n",
      "gold score -361.3223825331199\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "Working on symbol:  j (54)\n",
      "Running Time for this symbol: 54.65 seconds.\n",
      "Best score:  -504.22245237900006 Worst score:  -519.5037715950007\n",
      "gold score -363.1344102331199\n",
      "Wrong Wrong Wrong Wrong Wrong Wrong Wrong Wrong!\n",
      "CPU times: user 4h 7min 49s, sys: 1h 38min 13s, total: 5h 46min 2s\n",
      "Wall time: 5h 55min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# single core version\n",
    "# mappings = beam_search(cipher_desc['content'], ext_order, ext_limits, 1000000)\n",
    "# multiprocessing version\n",
    "mappings = beam_search_mp(cipher_desc['content'], ext_order, ext_limits, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilikekillsneheahleraceneaitisthrnconnaissuroopdntthinkillinewilderresacoenosmeetrecansaretitsharaattineposnernarelodillcokillsaretoiaeesretresherhatcosilliteaqhampnceitseerenrestaochraeatsitedonsmocksandwitoaeiolchpretthesshnstiacorpwhenitieswillremarooniahisrdicauttellsopshirekilledwillrecarerdelarasiwillnoteiradonrdairerecentedonwillcodthelaitawtomuchhrdcollactineadeleresnoordansaslideareasiesaretohhiss\n"
     ]
    }
   ],
   "source": [
    "mapping = mappings[0][0]\n",
    "decipher_text = ''\n",
    "for char in cipher_desc['content']:\n",
    "    decipher_text += mapping[char]\n",
    "print(decipher_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Decipherment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import collections\n",
    "import pprint\n",
    "import math\n",
    "import bz2\n",
    "import copy\n",
    "from random import shuffle\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us read in the cipher text from the `data` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    if filename[-4:] == \".bz2\":\n",
    "        with bz2.open(filename, 'rt') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    return content\n",
    "\n",
    "cipher = read_file(\"data/cipher.txt\")\n",
    "#print(cipher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the default solution we need to compute statistics like length, number of symbols/letters, \n",
    "unique occurences, frequencies and relative frequencies of a given file. This is done in the function `get_statistics` below.\n",
    "\n",
    "While using `get_statistics`, make sure that `cipher=True` is set when the input is a ciphertext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(content, cipher=True):\n",
    "    stats = {}\n",
    "    content = list(content)\n",
    "    split_content = [x for x in content if x != '\\n' and x!=' ']\n",
    "    length = len(split_content)\n",
    "    symbols = set(split_content)\n",
    "    uniq_sym = len(list(symbols))\n",
    "    freq = collections.Counter(split_content)\n",
    "    rel_freq = {}\n",
    "    for sym, frequency in freq.items():\n",
    "        rel_freq[sym] = (frequency/length)*100\n",
    "        \n",
    "    if cipher:\n",
    "        stats = {'content':split_content, 'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    else:\n",
    "        stats = {'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cipher_desc = get_statistics(cipher, cipher=True)\n",
    "#pp.pprint(cipher_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default solution matches the frequency of symbols in the cipher text with frequency of letters in the plaintext language (in this case, English). Note that this is just some text in English used to compute letter frequencies. We do not have access to the real plaintext in this homework. \n",
    "\n",
    "In order to do compute plaintext frequencies, we use an English dataset has no punctuation or spaces and all characters are lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plaintext description\n",
    "#plaintxt = read_file(\"data/default.wiki.txt.bz2\")\n",
    "#plaintxt_desc = get_statistics(plaintxt, cipher=False)\n",
    "#pp.pprint(plaintxt_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the tools we need to describe the default solution to this homework.\n",
    "\n",
    "We use a simple frequency matching heuristic to map cipher symbols to English letters.\n",
    "\n",
    "We match the frequencies using the function $f(\\cdot)$ of each cipher symbol $c$ with each English letter $e$:\n",
    "\n",
    "$$h_{c,e} = | \\log(\\frac{f(c)}{f(e)})) | $$\n",
    "\n",
    "For each cipher text symbol $c$ we then compute the most likely plain text symbol $e$ by sorting based on the above score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# default : frequency matching heuristic\n",
    "\n",
    "# Notice how the candidate mappings, a.k.a hypotheses, are first scored with a measure of quality and, \n",
    "# then, the best scoring hypothesis is chosen as the winner. \n",
    "\n",
    "# The plaintext letters from the winner are then mapped to the respective ciphertext symbols.\n",
    "# \"\"\"\n",
    "\n",
    "# def find_mappings(ciphertext, plaintext):\n",
    "#     mappings = defaultdict(dict)\n",
    "#     hypotheses = defaultdict(dict)\n",
    "#     # calculate alignment scores\n",
    "#     for symbol in ciphertext['vocab']:\n",
    "#         for letter in plaintext['vocab']:\n",
    "#             hypotheses[symbol][letter] = abs(math.log((ciphertext['relative_freq'][symbol]/plaintext['relative_freq'][letter])))\n",
    "    \n",
    "#     # find winner\n",
    "#     for sym in hypotheses.keys():\n",
    "#         #mappings[sym] = min(lemma_alignment[sym], key=lemma_alignment[sym].get)\n",
    "#         winner = sorted(hypotheses[sym].items(), key=lambda kv: kv[1])\n",
    "#         mappings[sym] = winner[1][0]\n",
    "    \n",
    "#     return mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this scoring function we map the cipher symbol `∆` to `v` in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∆ maps to v\n",
      "\n",
      "defaultdict(<class 'dict'>, {'Z': 'g', 'P': 'm', 'H': 'g', 'À': 'g', '√': 'b', 'ƒ': 'b', '“': 'b', '∫': 'm', '–': 'b', 'V': 'g', '^': 'b', 'O': 'b', 'E': 'g', 'Ω': 'v', '∑': 'u', '+': 'g', 'I': 'm', 'µ': 'g', '•': 'b', 'º': 'd', 'Ã': 'y', '£': 'g', '\\\\': 'y', 'R': 'u', 'y': 'u', '∆': 'v', 'T': 'b', 'N': 'b', '§': 'k', 'S': 'b', 'F': 'b', 'Q': 'y', 'π': 'b', '¢': 'k', '∏': 'g', 'D': 'b', 'K': 'y', 'B': 'u', 'u': 'u', '∞': 'g', 'X': 'g', '—': 'l', '≈': 'u', '‘': 'b', 'L': 'g', 'æ': 'g', 'G': 'b', 'j': 'x', 'Ç': 'y', '/': 'b', 'M': 'g', 'J': 'b', 'W': 'g', 'A': 'g'})\n"
     ]
    }
   ],
   "source": [
    "# mapping = find_mappings(cipher_desc, plaintxt_desc)\n",
    "# print(\"∆ maps to {}\\n\".format(mapping['∆']))\n",
    "# print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default solution to this decipherment problem is to take each cipher symbol and map it to the most likely English letter as provided by the `find_mappings` function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmmbgbuumgbubbgbugggububgdgmbyyluugbubumgvlbbbyubggbkbduumbugumvuylggbgggbbbybbgggugubglbbdymgglgggkbkubbmugybglbubybuugbbmuubglgggubuugbgylbmgglyggggbduumbugxbgybkuguggbgbbbggmggbggybuggmdbugbubybubbgbygmggguubmggbggygbbbmybggdgggybgggkmkubggduuggyggbbbmbbbbyvuugvbkbmmmgbggbbgbdmmgvgmuugbuglglgbugbgbdgdumbbguubggbulgbblgggubuyggbugdmugbggybugdkggbbyvgyblgubuugugmbugybmbbgbbbblggbmgbumygggggbdgmglggggbumg\n"
     ]
    }
   ],
   "source": [
    "# english_text = []\n",
    "# for symbol in cipher_desc['content']:\n",
    "#     english_text.append(mapping[symbol])\n",
    "# decipherment = ('').join(english_text)\n",
    "# print(decipherment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the default solution provides a very bad decipherment. Your job is to make it better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Baseline - Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from ngram import LM\n",
    "from nlm import *\n",
    "\n",
    "lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)\n",
    "model = load_model(\"data/mlstm_ns.pt\", cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Function\n",
    "Ref to <i>Decipherment of Substitution Ciphers with Neural Language Models {Nishant Kambhatla et al}<i>   \n",
    "3.3 Frequency Matching Heuristic   \n",
    "$$ SCORE(\\phi^\\prime) = SCORE(\\phi) + NEW(\\phi^\\prime) − FMH(\\phi^\\prime) $$\n",
    "$$ where\\ \\ \\ FMH(\\phi^\\prime) =  |\\ log (\\frac{ν(f)}{ν(e)})\\ |\\ \\ \\  f ∈ \\forall_f , e ∈ V_e$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Frequency Matching Heuristic\n",
    "    new_map should contain only 1 mapping (by paper)\n",
    "\"\"\"\n",
    "def fmh(new_map):\n",
    "    sum = 0\n",
    "    for f, e in new_map.items():\n",
    "        sum += abs(math.log(cipher_desc['relative_freq'][f] / plaintxt_desc['relative_freq'][e]))\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_dict(string, *list_of_dict):\n",
    "    for d in list_of_dict:\n",
    "        for k, v in d.items():\n",
    "            string = string.replace(k, v)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(old_score, phi_p, new_map, use_nlm=False):\n",
    "    content =''.join(cipher_desc['content'])\n",
    "    nlm_map = {}\n",
    "    if not use_nlm:\n",
    "        mask = {}\n",
    "        for i in set(content):\n",
    "            if i in phi_p:\n",
    "                mask.update({i : 'o'})\n",
    "            else:\n",
    "                mask.update({i : '_'})\n",
    "        mask = replace_dict(content, mask)\n",
    "    else:\n",
    "        seq = ''\n",
    "        mask = ''\n",
    "        for char in content:\n",
    "            if char in phi_p:\n",
    "                seq += phi_p[char]\n",
    "                mask += 'o'\n",
    "            elif len(seq) > 10 and seq != '':\n",
    "                # Global Rest Cost Estimation\n",
    "                sample_chars = [i for i in next_chars(seq, True, model) if i[0] != ' '] \n",
    "                shuffle(sample_chars)\n",
    "                sample_char = sample_chars[0][0]\n",
    "                nlm_map.update({char: sample_char})\n",
    "                seq += sample_char\n",
    "                mask += 'o'\n",
    "            else:\n",
    "                seq = ''\n",
    "                mask += '_'\n",
    "    new_score = lm.score_bitstring(replace_dict(content, phi_p, nlm_map), mask)\n",
    "    return old_score + new_score - fmh(new_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'º∫P/Z/uB∫ÀOR•–X•B\\nWV+≈GyF∞ºHPπKÇ—y≈\\nMJy^uIÀΩ—T‘NQyDµ£\\nS¢/º∑BPORAu∫∆RÃ—E\\nÀ^LMZJƒ“\\\\–FHVW≈æy\\nπ+—GDºKI£∞—Xæµ§S¢\\nRN‘IyEÃOæ—GBTQS∑B\\nLƒ/P∑BπX—EHMu^RRÀ\\n√ZK—–I£W—ÇæµLM“º∑\\nBPDR+j•∞\\\\N¢≈EuHÀF\\nZ√–OVWIµ+‘L£Ã^R∞H\\nIºDR∏Ty“\\\\ƒ≈/πXJQA\\nPµMæRu‘∫L£NVEKH•G\\n“IÇJÀµºæLMÃNA£Z¢P\\n§u–ÀAº∑BVW\\\\+VT‘OP\\n^•S“Ã∆u≈∞ΩD§G∫∫IM\\nNÀ£S√E/º∫∫Z∆AP∑BV\\n–≈X—W—∏F∑æ√+πºAºB\\n∫OTµRu√+∏ƒy—∏^S—W\\nVZ≈GyKE∏TyAº∫∑L‘∏\\nHÇFBXº§XADƒ\\\\ΩLÇ•—\\n∏≈ƒ∑∑∞≈µPORXQF∫G√\\nZπJT‘—∏æJI+“BPQW∞\\nVEX“ºWI∞—EHM£•uIÀ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beam Search for Solving Substitution Ciphers   \n",
    "6.2 Zodiac-408 Cipher - P.1574   \n",
    "We use extension limits with nmax = 8 and histogram pruning with beam sizes of 10k up to 10M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(ext_order, ext_limits=8, beam_size=1000):\n",
    "    Hs, Ht = [], []\n",
    "    cardinality = 0\n",
    "    Hs.append(({}, 0))\n",
    "    while (cardinality < len(ext_order)):\n",
    "        f = ext_order[cardinality]\n",
    "        for phi, old_score in Hs:\n",
    "            #with Pool(processes=2) as pool:\n",
    "            for e in sorted(plaintxt_desc['vocab']):\n",
    "                phi_p = copy.deepcopy(phi)\n",
    "                new_map = {f: e}\n",
    "                phi_p.update(new_map)\n",
    "                counts = len([v for k, v in phi_p.items() if v == e])\n",
    "                if counts <= ext_limits:\n",
    "                    score_t = score(old_score, phi_p, new_map)\n",
    "                    Ht.append((phi_p, score_t))\n",
    "        Ht = sorted(Ht, key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "        print(cardinality)\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cipher = read_file(\"data/cipher.txt\")\n",
    "# cipher_desc = get_statistics(cipher, cipher=True)\n",
    "# plaintxt = read_file(\"data/default.wiki.txt.bz2\")\n",
    "# plaintxt_desc = get_statistics(plaintxt, cipher=False)\n",
    "ext_order = [text for text, _ in sorted(cipher_desc['frequencies'].items(), key=lambda x: x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-9ee8baa1a0c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mext_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-766e24dd37a2>\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(ext_order, ext_limits, beam_size)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mphi_p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mext_limits\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mscore_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                     \u001b[0mHt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mHt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-17fa2b8e4895>\u001b[0m in \u001b[0;36mscore\u001b[1;34m(old_score, phi_p, new_map, use_nlm)\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'o'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreplace_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mapping = beam_search(ext_order, 4, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'º∫P/Z/uB∫ÀOR•–X•B\\nWV+≈GyF∞ºHPπKÇ—y≈\\nMJy^uIÀΩ—T‘NQyDµ£\\nS¢/º∑BPORAu∫∆RÃ—E\\nÀ^LMZJƒ“\\\\–FHVW≈æy\\nπ+—GDºKI£∞—Xæµ§S¢\\nRN‘IyEÃOæ—GBTQS∑B\\nLƒ/P∑BπX—EHMu^RRÀ\\n√ZK—–I£W—ÇæµLM“º∑\\nBPDR+j•∞\\\\N¢≈EuHÀF\\nZ√–OVWIµ+‘L£Ã^R∞H\\nIºDR∏Ty“\\\\ƒ≈/πXJQA\\nPµMæRu‘∫L£NVEKH•G\\n“IÇJÀµºæLMÃNA£Z¢P\\n§u–ÀAº∑BVW\\\\+VT‘OP\\n^•S“Ã∆u≈∞ΩD§G∫∫IM\\nNÀ£S√E/º∫∫Z∆AP∑BV\\n–≈X—W—∏F∑æ√+πºAºB\\n∫OTµRu√+∏ƒy—∏^S—W\\nVZ≈GyKE∏TyAº∫∑L‘∏\\nHÇFBXº§XADƒ\\\\ΩLÇ•—\\n∏≈ƒ∑∑∞≈µPORXQF∫G√\\nZπJT‘—∏æJI+“BPQW∞\\nVEX“ºWI∞—EHM£•uIÀ'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the following cells. They are for grading against the reference decipherment. Based on the clues provided in the decipherment homework description, you can easily find a reasonable reference text online for this cipher text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  100.0 Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ATTENTION!\n",
    "For grading purposes only. Don't bundle with the assignment. \n",
    "Make sure '_ref.txt' is removed from the 'data' directory before publishing.\n",
    "\"\"\"\n",
    "\n",
    "def read_gold(gold_file):\n",
    "    with open(gold_file) as f:\n",
    "        gold = f.read()\n",
    "    f.close()\n",
    "    gold = list(gold.strip())\n",
    "    return gold\n",
    "\n",
    "def symbol_error_rate(dec, _gold):\n",
    "    gold = read_gold(_gold)\n",
    "    correct = 0\n",
    "    if len(gold) == len(dec):\n",
    "        for (d,g) in zip(dec, gold):\n",
    "            if d==g:\n",
    "                correct += 1\n",
    "    wrong = len(gold)-correct\n",
    "    error = wrong/len(gold)\n",
    "    \n",
    "    return error\n",
    "    \n",
    "# gold decipherment\n",
    "gold_file = \"data/_ref_Zodiac_408.txt\"\n",
    "ser = symbol_error_rate(decipherment, gold_file)\n",
    "print('Error: ', ser*100, 'Accuracy: ', (1-ser)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

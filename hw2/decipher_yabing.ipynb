{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Decipherment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import defaultdict, Counter\n",
    "import collections\n",
    "import pprint\n",
    "import math\n",
    "import bz2\n",
    "from ngram import *\n",
    "import sys, string\n",
    "import copy\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "import itertools\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us read in the cipher text from the `data` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "º∫P/Z/uB∫ÀOR•–X•B\n",
      "WV+≈GyF∞ºHPπKÇ—y≈\n",
      "MJy^uIÀΩ—T‘NQyDµ£\n",
      "S¢/º∑BPORAu∫∆RÃ—E\n",
      "À^LMZJƒ“\\–FHVW≈æy\n",
      "π+—GDºKI£∞—Xæµ§S¢\n",
      "RN‘IyEÃOæ—GBTQS∑B\n",
      "Lƒ/P∑BπX—EHMu^RRÀ\n",
      "√ZK—–I£W—ÇæµLM“º∑\n",
      "BPDR+j•∞\\N¢≈EuHÀF\n",
      "Z√–OVWIµ+‘L£Ã^R∞H\n",
      "IºDR∏Ty“\\ƒ≈/πXJQA\n",
      "PµMæRu‘∫L£NVEKH•G\n",
      "“IÇJÀµºæLMÃNA£Z¢P\n",
      "§u–ÀAº∑BVW\\+VT‘OP\n",
      "^•S“Ã∆u≈∞ΩD§G∫∫IM\n",
      "NÀ£S√E/º∫∫Z∆AP∑BV\n",
      "–≈X—W—∏F∑æ√+πºAºB\n",
      "∫OTµRu√+∏ƒy—∏^S—W\n",
      "VZ≈GyKE∏TyAº∫∑L‘∏\n",
      "HÇFBXº§XADƒ\\ΩLÇ•—\n",
      "∏≈ƒ∑∑∞≈µPORXQF∫G√\n",
      "ZπJT‘—∏æJI+“BPQW∞\n",
      "VEX“ºWI∞—EHM£•uIÀ\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    if filename[-4:] == \".bz2\":\n",
    "        with bz2.open(filename, 'rt', encoding='utf8') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename, 'r', encoding='utf8') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    return content\n",
    "\n",
    "cipher = read_file(\"data/cipher.txt\")\n",
    "print(cipher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the default solution we need to compute statistics like length, number of symbols/letters, \n",
    "unique occurences, frequencies and relative frequencies of a given file. This is done in the function `get_statistics` below.\n",
    "\n",
    "While using `get_statistics`, make sure that `cipher=True` is set when the input is a ciphertext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(content, cipher=True):\n",
    "    stats = {}\n",
    "    content = list(content)\n",
    "    split_content = [x for x in content if x != '\\n' and x!=' ']\n",
    "    length = len(split_content)\n",
    "    symbols = set(split_content)\n",
    "    uniq_sym = len(list(symbols))\n",
    "    freq = collections.Counter(split_content)\n",
    "    rel_freq = {}\n",
    "    for sym, frequency in freq.items():\n",
    "        rel_freq[sym] = (frequency/length)*100\n",
    "        \n",
    "    if cipher:\n",
    "        stats = {'content':split_content, 'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    else:\n",
    "        stats = {'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ATTENTION!\n",
    "For grading purposes only. Don't bundle with the assignment. \n",
    "Make sure '_ref.txt' is removed from the 'data' directory before publishing.\n",
    "\"\"\"\n",
    "\n",
    "def read_gold(gold_file):\n",
    "    with open(gold_file) as f:\n",
    "        gold = f.read()\n",
    "    f.close()\n",
    "    gold = list(gold.strip())\n",
    "    return gold\n",
    "\n",
    "def symbol_error_rate(dec, _gold):\n",
    "    gold = read_gold(_gold)\n",
    "    correct = 0\n",
    "    if len(gold) == len(dec):\n",
    "        for (d,g) in zip(dec, gold):\n",
    "            if d==g:\n",
    "                correct += 1\n",
    "    wrong = len(gold)-correct\n",
    "    error = wrong/len(gold)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cipher_desc = get_statistics(cipher, cipher=True)\n",
    "#pp.pprint(cipher_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the 6-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequence = 'In a few cases, a multilingual artifact has been necessary to facilitate decipherment, the Rosetta Stone being the classic example. Statistical techniques provide another pathway to decipherment, as does the analysis of modern languages derived from ancient languages in which undeciphered texts are written. Archaeological and historical information is helpful in verifying hypothesized decipherments.'\n",
    "\n",
    "# lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=True)\n",
    "lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "getsizeof(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320.0000915527344"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getsizeof(lm.table) / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ngram.LM at 0x3880c358>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "deepcopy(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a few cases, a multilingual artifact has been necessary to facilitate decipherment, the Rosetta Stone being the classic example. Statistical techniques provide another pathway to decipherment, as does the analysis of modern languages derived from ancient languages in which undeciphered texts are written. Archaeological and historical information is helpful in verifying hypothesized decipherments.\n",
      "{2: 3, 3: 4, 7: 8, 8: 9, 9: 10}\n",
      "-8.10905897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TOTAL LM LOGPROB: -221.09434842188\n",
      "TOTAL LM LOGPROB: -9.76947916\n",
      "TOTAL LM LOGPROB: -40.57683077\n"
     ]
    }
   ],
   "source": [
    "print(sequence)\n",
    "lm_logprob = lm.score_seq(sequence)\n",
    "print(\"TOTAL LM LOGPROB: {}\".format(lm_logprob), file=sys.stderr)\n",
    "\n",
    "print(\"TOTAL LM LOGPROB: {}\".format(lm.score_seq('this is the text.')), file=sys.stderr)\n",
    "print(\"TOTAL LM LOGPROB: {}\".format(lm.score_seq('jasbklfhthejkldhf')), file=sys.stderr)\n",
    "\n",
    "print(lm.get_bitstring_spans('..oo...ooo..'))\n",
    "print(lm.score_bitstring('thisisatest', 'oo...oo.ooo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Implementation for Reference 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_sharp_n(cipher_desc, symbols_found, n_order):\n",
    "    '''\n",
    "    finds the #n for order n_order\n",
    "    cipher_desc -- cipher statistics\n",
    "    symbols_found -- list of single character string,\n",
    "                     specifies the list of symbols have been placed in the extention order\n",
    "    n_order -- int, specifies the order of n-gram\n",
    "    '''\n",
    "    sharp_n = 0\n",
    "    for i in range(len(cipher_desc['content'])-n_order+1):\n",
    "        #flag = True\n",
    "        for j in range(i, i+n_order, 1):\n",
    "            if cipher_desc['content'][j] not in symbols_found:\n",
    "                break\n",
    "            if j == (i+n_order-1):\n",
    "                sharp_n += 1\n",
    "                #print(cipher_desc['content'][i:i+n_order])\n",
    "    return sharp_n            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# test the function above\n",
    "sharp_n = find_sharp_n(cipher_desc, ['—', 'º'], 2)\n",
    "print(sharp_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_ext_order(cipher_desc, topn=100, weights=[1,1,1,1,2,3]):\n",
    "    '''\n",
    "    finds the best order of deciphering cipher symbols (find best extention order)\n",
    "    cipher_desc -- cipher statistics\n",
    "    topn -- int, number of best trees we want to keep during iteration\n",
    "    weights -- list of int, weight for #n, n varies from 1 to 6\n",
    "    '''\n",
    "    # symbols_found = list()\n",
    "    # symbols_found.append(sorted(cipher_desc['frequencies'], key=cipher_desc['frequencies'].get, reverse=True)[0])\n",
    "    # symbols already found with score\n",
    "    Hs = [([], 0)]\n",
    "    # hypothesis extended symbols with score\n",
    "    Ht = []\n",
    "    # initialize the cardinality (number of unique cipher text)\n",
    "    cardinality = 0\n",
    "    # list of cipher characters\n",
    "    Ve = sorted(cipher_desc['frequencies'], key=cipher_desc['frequencies'].get, reverse=True)\n",
    "    while cardinality < cipher_desc['vocab_length']:\n",
    "    #while cardinality < 3:\n",
    "        for phi, previous_score in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = copy.deepcopy(phi)\n",
    "                if e in phi_prime:\n",
    "                    continue\n",
    "                else:\n",
    "                    phi_prime.append(e)\n",
    "                    this_score = 0\n",
    "                    for i in range(6):\n",
    "                        this_score += weights[i]*find_sharp_n(cipher_desc, phi_prime, i+1)\n",
    "                    Ht.append((phi_prime, this_score))\n",
    "        # prune the histogram\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]                    \n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "        print('Done with symbol number', cardinality, '; Current best score: ', Hs[0][1])\n",
    "        # print('Hs', Hs)\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with symbol number 1 ; Current best score:  16\n",
      "Done with symbol number 2 ; Current best score:  31\n",
      "Done with symbol number 3 ; Current best score:  50\n",
      "Done with symbol number 4 ; Current best score:  72\n",
      "Done with symbol number 5 ; Current best score:  96\n",
      "Done with symbol number 6 ; Current best score:  122\n",
      "Done with symbol number 7 ; Current best score:  144\n",
      "Done with symbol number 8 ; Current best score:  176\n",
      "Done with symbol number 9 ; Current best score:  206\n",
      "Done with symbol number 10 ; Current best score:  237\n",
      "Done with symbol number 11 ; Current best score:  268\n",
      "Done with symbol number 12 ; Current best score:  315\n",
      "Done with symbol number 13 ; Current best score:  369\n",
      "Done with symbol number 14 ; Current best score:  396\n",
      "Done with symbol number 15 ; Current best score:  428\n",
      "Done with symbol number 16 ; Current best score:  455\n",
      "Done with symbol number 17 ; Current best score:  485\n",
      "Done with symbol number 18 ; Current best score:  516\n",
      "Done with symbol number 19 ; Current best score:  545\n",
      "Done with symbol number 20 ; Current best score:  595\n",
      "Done with symbol number 21 ; Current best score:  630\n",
      "Done with symbol number 22 ; Current best score:  680\n",
      "Done with symbol number 23 ; Current best score:  722\n",
      "Done with symbol number 24 ; Current best score:  771\n",
      "Done with symbol number 25 ; Current best score:  818\n",
      "Done with symbol number 26 ; Current best score:  869\n",
      "Done with symbol number 27 ; Current best score:  924\n",
      "Done with symbol number 28 ; Current best score:  988\n",
      "Done with symbol number 29 ; Current best score:  1047\n",
      "Done with symbol number 30 ; Current best score:  1106\n",
      "Done with symbol number 31 ; Current best score:  1174\n",
      "Done with symbol number 32 ; Current best score:  1244\n",
      "Done with symbol number 33 ; Current best score:  1318\n",
      "Done with symbol number 34 ; Current best score:  1408\n",
      "Done with symbol number 35 ; Current best score:  1492\n",
      "Done with symbol number 36 ; Current best score:  1573\n",
      "Done with symbol number 37 ; Current best score:  1655\n",
      "Done with symbol number 38 ; Current best score:  1759\n",
      "Done with symbol number 39 ; Current best score:  1844\n",
      "Done with symbol number 40 ; Current best score:  1960\n",
      "Done with symbol number 41 ; Current best score:  2063\n",
      "Done with symbol number 42 ; Current best score:  2194\n",
      "Done with symbol number 43 ; Current best score:  2293\n",
      "Done with symbol number 44 ; Current best score:  2408\n",
      "Done with symbol number 45 ; Current best score:  2520\n",
      "Done with symbol number 46 ; Current best score:  2681\n",
      "Done with symbol number 47 ; Current best score:  2814\n",
      "Done with symbol number 48 ; Current best score:  2948\n",
      "Done with symbol number 49 ; Current best score:  3096\n",
      "Done with symbol number 50 ; Current best score:  3253\n",
      "Done with symbol number 51 ; Current best score:  3360\n",
      "Done with symbol number 52 ; Current best score:  3491\n",
      "Done with symbol number 53 ; Current best score:  3605\n",
      "Done with symbol number 54 ; Current best score:  3643\n",
      "Wall time: 15min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test the function above\n",
    "ext_order = find_ext_order(cipher_desc, topn=100, weights=[1,1,1,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reverse_mapping(reversed_mapping):\n",
    "#     mapping = dict()\n",
    "#     for key, values in reversed_mapping.items():\n",
    "#         for value in values:\n",
    "#             mapping[value] = key\n",
    "#     return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(phi, cipher, lm):\n",
    "    mapping = phi\n",
    "    partial_cipher = ''\n",
    "    bit_string = ''\n",
    "    #n_decipher = 0\n",
    "    for char in cipher:\n",
    "        if char in mapping.keys():\n",
    "            partial_cipher += mapping[char]\n",
    "            bit_string += 'o'\n",
    "            #n_decipher += 1\n",
    "        else:\n",
    "            partial_cipher += char\n",
    "            bit_string += '.'\n",
    "    # print(bit_string)\n",
    "    return lm.score_bitstring(partial_cipher, bit_string)\n",
    "def beam_search_old(cipher, ext_order, ext_limits=1, topn=1):\n",
    "    '''\n",
    "    finds the mappings between cipher char and plaintext char, returns the mapping dictionary\n",
    "    ext_order -- list, the unigram char list sorted by their count DESC\n",
    "    ext_limits -- int, defines maximum number of cipher char can be mapped to a plaintext char\n",
    "    topn -- int, defines the number of dictionaries we want to keep while pruning\n",
    "    '''\n",
    "    print('Number of unique symbols in cipher:', len(ext_order))\n",
    "    # mapping relationships already found with score\n",
    "    Hs = [(defaultdict(dict), 0)]\n",
    "    # hypothesis mapping relationships with score\n",
    "    Ht = []\n",
    "    # initialize the cardinality (number of unique cipher text)\n",
    "    cardinality = 0\n",
    "    # list of plaintext characters\n",
    "    Ve = [chr(i) for i in range(97, 123, 1)]\n",
    "    while cardinality < len(ext_order):\n",
    "    #while cardinality < 2:\n",
    "        f = ext_order[cardinality]\n",
    "        print('Working on symbol: ', f, f'({cardinality+1})')\n",
    "        for phi, previous_score in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = copy.deepcopy(phi)\n",
    "                new_map = {f: e}\n",
    "                phi_prime.update(new_map)\n",
    "                counts = len([v for k, v in phi_prime.items() if v == e])\n",
    "                if counts <= ext_limits:\n",
    "                    Ht.append((phi_prime, score(phi_prime, cipher, lm)))\n",
    "        # prune the histogram\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]                    \n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "        print('Current score: ', Hs[0][1])\n",
    "        #print('Hs', Hs)\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work(Hs):\n",
    "    ret = []\n",
    "    for phi, previous_score in Hs:\n",
    "        for e in Ve:\n",
    "            phi_prime = copy.deepcopy(phi)\n",
    "            new_map = {f: e}\n",
    "            phi_prime.update(new_map)\n",
    "            counts = len([v for k, v in phi_prime.items() if v == e])\n",
    "            if counts <= ext_limits:\n",
    "                ret.append((phi_prime, score(phi_prime, cipher, lm)))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(n, iterable):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_mp(cipher, ext_order, ext_limits=1, topn=1):\n",
    "    '''\n",
    "    finds the mappings between cipher char and plaintext char, returns the mapping dictionary\n",
    "    ext_order -- list, the unigram char list sorted by their count DESC\n",
    "    ext_limits -- int, defines maximum number of cipher char can be mapped to a plaintext char\n",
    "    topn -- int, defines the number of dictionaries we want to keep while pruning\n",
    "    '''\n",
    "    print('Number of unique symbols in cipher:', len(ext_order))\n",
    "    # mapping relationships already found with score\n",
    "    Hs = [(defaultdict(dict), 0)]\n",
    "    # hypothesis mapping relationships with score\n",
    "    Ht = []\n",
    "    # initialize the cardinality (number of unique cipher text)\n",
    "    cardinality = 0\n",
    "    # list of plaintext characters\n",
    "    Ve = [chr(i) for i in range(97, 123, 1)]\n",
    "    \n",
    "    N_JOBS = 3\n",
    "    p = Parallel(n_jobs=N_JOBS, verbose=2, )\n",
    "    \n",
    "    while cardinality < len(ext_order):\n",
    "    #while cardinality < 2:\n",
    "        f = ext_order[cardinality]\n",
    "        print('Working on symbol: ', f, f'({cardinality+1})')\n",
    "        jobs = list(grouper(math.ceil(len(Hs) / N_JOBS), Hs))\n",
    "\n",
    "        print(f\"Num of jobs {len(jobs)} w {len(jobs[0])}\")\n",
    "        Hts = p(delayed(work)(job) for job in jobs)\n",
    "        Ht = [e for l in Hts for e in l]\n",
    "        \n",
    "        # prune the histogram\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]                    \n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "        print('Current score: ', Hs[0][1])\n",
    "        #print('Hs', Hs)\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique symbols in cipher: 54\n",
      "Working on symbol:  — (1)\n",
      "Num of jobs 1 w 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "c:\\users\\yabguo\\desktop\\files\\personal\\gitrep~1\\nlpcla~1\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mappings = beam_search_mp(cipher_desc['content'], ext_order[0][0], 8, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mappings = beam_search_old(cipher_desc['content'], ext_order[0][0], 8, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teenintheareseashoreesisattentitieaairtraittogsinsearnttheresteneatearraiaitbestroesinetsnttreatassaaregoriearstshtsathrinethnatetatreeasittereotissratttheneedsabgreettasiserrorseoreareatrtneititbiennaassesasetoeregrettsstriaastsraagseireateastthrobertorersatanteainaseeragaeasenteeinsethreeatotistssentsthertsetseiiitiratoriesiteitistetroitishataasnibiristieittaesereassessinatotisarethesoareattoratetaestra\n",
      "score -499.1032521029998\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "mapping = mappings[0][0]\n",
    "decipher_text = ''\n",
    "for char in cipher_desc['content']:\n",
    "    decipher_text += mapping[char]\n",
    "print(decipher_text)\n",
    "print('score', lm.score_seq(decipher_text))\n",
    "print(len(decipher_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = mappings[0][0]\n",
    "decipher_text = ''\n",
    "for char in cipher_desc['content']:\n",
    "    decipher_text += mapping[char]\n",
    "print(decipher_text)\n",
    "print('score', lm.score_seq(decipher_text))\n",
    "print(len(decipher_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8602941176470589"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_error_rate(decipher_text, 'data/_ref_Zodiac_408.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new score function (should be more efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_new(cipher, phi, new_f, new_e, previous_score):\n",
    "    '''\n",
    "    scores the phi_prime based on the previous score, returns a dict\n",
    "    cipher -- list of single character string\n",
    "    phi -- dictionary, old mapping e->[f]\n",
    "    new_f -- single-character string, extended symbol\n",
    "    previous_score -- float, old score for phi\n",
    "    '''\n",
    "    mapping = phi\n",
    "    new_score = previous_score\n",
    "    lm_state = lm.begin()\n",
    "    for i in range(len(cipher)):\n",
    "        char = cipher[i]\n",
    "        if char in mapping.keys():\n",
    "            token = mapping[char]\n",
    "            ngram = lm_state + (token,)\n",
    "            while len(ngram)> 0:\n",
    "                if ngram in lm.table:\n",
    "                    lm_state = ngram[-lm.history:]\n",
    "                    break\n",
    "                else: #backoff\n",
    "                    ngram = ngram[1:]\n",
    "            if len(ngram)==0:\n",
    "                lm_state = ()\n",
    "        elif char == new_f:\n",
    "            (lm_state, logprob) = lm.score(lm_state, new_e)\n",
    "            new_score += logprob\n",
    "        else:\n",
    "            lm_state = ()  \n",
    "    return new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous lm_state ('<s>',)\n",
      "lm_state ('<s>', 't')\n",
      "logrob2222 -0.7213777\n",
      "previous lm_state ('<s>', 't')\n",
      "lm_state ('<s>', 't', 'h')\n",
      "logrob2222 -0.06716067\n",
      "previous lm_state ('<s>', 't', 'h')\n",
      "lm_state ('<s>', 't', 'h', 'i')\n",
      "logrob2222 -1.644994\n",
      "previous lm_state ('<s>', 't', 'h', 'i')\n",
      "lm_state ('<s>', 't', 'h', 'i', 's')\n",
      "logrob2222 -0.08672674\n",
      "previous lm_state ('<s>', 't', 'h', 'i', 's')\n",
      "lm_state ('t', 'h', 'i', 's', 'i')\n",
      "logrob2222 -0.9207457\n",
      "previous lm_state ('t', 'h', 'i', 's', 'i')\n",
      "lm_state ('h', 'i', 's', 'i', 's')\n",
      "logrob2222 -0.2430651\n",
      "previous lm_state ('h', 'i', 's', 'i', 's')\n",
      "lm_state ('i', 's', 'i', 's', 'a')\n",
      "logrob2222 -0.7108436\n",
      "previous lm_state ('i', 's', 'i', 's', 'a')\n",
      "lm_state ('s', 'i', 's', 'a', 't')\n",
      "logrob2222 -1.269513\n",
      "previous lm_state ('s', 'i', 's', 'a', 't')\n",
      "lm_state ('i', 's', 'a', 't', 'e')\n",
      "logrob2222 -1.071304\n",
      "previous lm_state ('i', 's', 'a', 't', 'e')\n",
      "lm_state ('s', 'a', 't', 'e', 's')\n",
      "logrob2222 -1.071436\n",
      "previous lm_state ('s', 'a', 't', 'e', 's')\n",
      "lm_state ('a', 't', 'e', 's', 't')\n",
      "logrob2222 -0.1279864\n",
      "-11.05281791\n"
     ]
    }
   ],
   "source": [
    "sequence = 'thisisatest'\n",
    "bitstring = 'ooooooooooo'\n",
    "bitstring_ = 'oo..ooooooo'\n",
    "\n",
    "spans = lm.get_bitstring_spans(bitstring)\n",
    "seq_by_bits = [ sequence[i] if i in spans else '\\t' for i in range(len(sequence)) ]\n",
    "lm_state = lm.begin()\n",
    "lm_logprob = 0.0 \n",
    "for token in list(seq_by_bits):\n",
    "    if token == '\\t': # should we skip this token?\n",
    "        lm_state = ()\n",
    "        continue\n",
    "    print('previous lm_state', lm_state)\n",
    "    (lm_state, logprob) = lm.score(lm_state, token)\n",
    "    lm_logprob += logprob\n",
    "\n",
    "    print('lm_state', lm_state)\n",
    "    print('logrob2222', logprob)\n",
    "lm_logprob += lm.end(lm_state)\n",
    "print(lm_logprob)\n",
    "# -11.05281791\n",
    "# -18.7161607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(cipher, ext_order, ext_limits=1, topn=1):\n",
    "    '''\n",
    "    finds the mappings between cipher char and plaintext char, returns the mapping dictionary\n",
    "    ext_order -- list, the unigram char list sorted by their count DESC\n",
    "    ext_limits -- int, defines maximum number of cipher char can be mapped to a plaintext char\n",
    "    topn -- int, defines the number of dictionaries we want to keep while pruning\n",
    "    '''\n",
    "    print('Number of unique symbols in cipher:', len(ext_order))\n",
    "    # mapping relationships already found with score\n",
    "    Hs = [(defaultdict(dict), 0)]\n",
    "    # hypothesis mapping relationships with score\n",
    "    Ht = []\n",
    "    # initialize the cardinality (number of unique cipher text)\n",
    "    cardinality = 0\n",
    "    # list of plaintext characters\n",
    "    Ve = [chr(i) for i in range(97, 123, 1)]\n",
    "    while cardinality < len(ext_order):\n",
    "    #while cardinality < 2:\n",
    "        f = ext_order[cardinality]\n",
    "        print('Working on symbol: ', f, f'({cardinality+1})')\n",
    "        for phi, previous_score in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = copy.deepcopy(phi)\n",
    "                new_map = {f: e}\n",
    "                phi_prime.update(new_map)\n",
    "                counts = len([v for k, v in phi_prime.items() if v == e])\n",
    "                if counts <= ext_limits:\n",
    "                    Ht.append((phi_prime, score_new(cipher, phi, f, e, previous_score)))\n",
    "        # prune the histogram\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]                    \n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "        print('Current score: ', Hs[0][1])\n",
    "        #print('Hs', Hs)\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_most_cipher_vocab = list()\n",
    "for cipher_char in reversed(cipher_desc['content']):\n",
    "    if cipher_char not in right_most_cipher_vocab:\n",
    "        right_most_cipher_vocab.append(cipher_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ext_order.pkl', 'wb') as fh:\n",
    "#     pickle.dump(ext_order, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ext_order.pkl', 'rb') as fh:\n",
    "    ext_order = pickle.load(fh, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique symbols in cipher: 54\n",
      "Working on symbol:  — (1)\n",
      "Current score:  -14.649315199999997\n",
      "Working on symbol:  ∑ (2)\n",
      "Current score:  -24.38143299999999\n",
      "Working on symbol:  B (3)\n",
      "Current score:  -35.98365760000001\n",
      "Working on symbol:  P (4)\n",
      "Current score:  -44.349759600000034\n",
      "Working on symbol:  º (5)\n",
      "Current score:  -57.81347020000007\n",
      "Working on symbol:  ∫ (6)\n",
      "Current score:  -69.70347510000002\n",
      "Working on symbol:  A (7)\n",
      "Current score:  -76.9784770000001\n",
      "Working on symbol:  / (8)\n",
      "Current score:  -82.84680000000007\n",
      "Working on symbol:  Z (9)\n",
      "Current score:  -91.55581070000004\n",
      "Working on symbol:  ∆ (10)\n",
      "Current score:  -94.33437120000005\n",
      "Working on symbol:  u (11)\n",
      "Current score:  -104.13269230000006\n",
      "Working on symbol:  O (12)\n",
      "Current score:  -111.65146800000007\n",
      "Working on symbol:  R (13)\n",
      "Current score:  -122.1242165800001\n",
      "Working on symbol:  À (14)\n",
      "Current score:  -131.59201208000007\n",
      "Working on symbol:  Ã (15)\n",
      "Current score:  -136.28468161299998\n",
      "Working on symbol:  E (16)\n",
      "Current score:  -145.28831491300002\n",
      "Working on symbol:  ^ (17)\n",
      "Current score:  -151.68065494999996\n",
      "Working on symbol:  √ (18)\n",
      "Current score:  -157.19194885\n",
      "Working on symbol:  – (19)\n",
      "Current score:  -163.4163481\n",
      "Working on symbol:  V (20)\n",
      "Current score:  -170.10415004999993\n",
      "Working on symbol:  W (21)\n",
      "Current score:  -179.7080180499999\n",
      "Working on symbol:  K (22)\n",
      "Current score:  -184.0890542500002\n",
      "Working on symbol:  I (23)\n",
      "Current score:  -195.48675964999998\n",
      "Working on symbol:  £ (24)\n",
      "Current score:  -203.61474835000007\n",
      "Working on symbol:  ∞ (25)\n",
      "Current score:  -212.69039225000003\n",
      "Working on symbol:  H (26)\n",
      "Current score:  -220.08446335000016\n",
      "Working on symbol:  M (27)\n",
      "Current score:  -227.80875809999986\n",
      "Working on symbol:  • (28)\n",
      "Current score:  -234.32673591999992\n",
      "Working on symbol:  X (29)\n",
      "Current score:  -243.3934271599998\n",
      "Working on symbol:  ≈ (30)\n",
      "Current score:  -253.45241668999967\n",
      "Working on symbol:  π (31)\n",
      "Current score:  -258.91552891\n",
      "Working on symbol:  F (32)\n",
      "Current score:  -265.2803806199999\n",
      "Working on symbol:  “ (33)\n",
      "Current score:  -272.04246356999994\n",
      "Working on symbol:  S (34)\n",
      "Current score:  -278.1893550849999\n",
      "Working on symbol:  N (35)\n",
      "Current score:  -283.84250997999993\n",
      "Working on symbol:  L (36)\n",
      "Current score:  -293.73930747\n",
      "Working on symbol:  µ (37)\n",
      "Current score:  -302.68382957999995\n",
      "Working on symbol:  æ (38)\n",
      "Current score:  -310.4323105810003\n",
      "Working on symbol:  + (39)\n",
      "Current score:  -320.07013620000026\n",
      "Working on symbol:  G (40)\n",
      "Current score:  -327.0499895100004\n",
      "Working on symbol:  y (41)\n",
      "Current score:  -336.95902233799995\n",
      "Working on symbol:  ‘ (42)\n",
      "Current score:  -343.981215538\n",
      "Working on symbol:  ∏ (43)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sorted_keys = sorted(cipher_desc['frequencies'], key=cipher_desc['frequencies'].get, reverse=True)\n",
    "#reversed_mappings = beam_search(cipher_desc['content'], sorted_keys, 3, 100)\n",
    "#reversed_mappings = beam_search(cipher_desc['content'], right_most_cipher_vocab, 8, 1000)\n",
    "mappings = beam_search(cipher_desc['content'], ext_order[0][0], 8, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping = mappings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seehihaheareastahseatsaiosteesheattaanatareaioratrrinhsthereeaeneieaanttiaoeusitesthaeaestsstroethroineoitaairhesharithtohetheteattaneearisestrsehhrttestheteamaouontaataiirsrestraitrineottstenaaeuothetareertheaietroeastasethaarshttioerineoasaesthesuaeairenaieinatortoseettoarirahseeineethesttesenithraesesherarearanoaennieseitsasanaaesettinthihtsotetourthaentottotreretriesrieaaienhataehersoeatesstoeattraata\n",
      "score -597.1548610020002\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "decipher_text = ''\n",
    "for char in cipher_desc['content']:\n",
    "    decipher_text += mapping[char]\n",
    "print(decipher_text)\n",
    "print('score', lm.score_seq(decipher_text))\n",
    "print(len(decipher_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilikekillingpeoplebecauseitissomuchfunitismorefunthankillingwildgameintheforrestbecausemanisthemostdangeroueanamalofalltokillsomethinggivesmethemostthrillingexperenceitisevenbetterthangettingyourrocksoffwithagirlthebestpartofitisthaewhenidieiwillbereborninparadicesndalltheihavekilledwillbecomemyslavesiwillnotgiveyoumynamebecauseyouwilltrytosloidownorstopmycollectiogofslavesformyafterlifeebeorietemethhpiti\n",
      "score -359.0030393831197\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "with open('data/_ref_Zodiac_408.txt', 'r') as fh:\n",
    "    ground_truth = fh.read()\n",
    "print(ground_truth)\n",
    "print('score', lm.score_seq(ground_truth))\n",
    "print(len(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8848039215686274"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_error_rate(decipher_text, 'data/_ref_Zodiac_408.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the default solution provides a very bad decipherment. Your job is to make it better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the following cells. They are for grading against the reference decipherment. Based on the clues provided in the decipherment homework description, you can easily find a reasonable reference text online for this cipher text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ATTENTION!\n",
    "For grading purposes only. Don't bundle with the assignment. \n",
    "Make sure '_ref.txt' is removed from the 'data' directory before publishing.\n",
    "\"\"\"\n",
    "\n",
    "def read_gold(gold_file):\n",
    "    with open(gold_file) as f:\n",
    "        gold = f.read()\n",
    "    f.close()\n",
    "    gold = list(gold.strip())\n",
    "    return gold\n",
    "\n",
    "def symbol_error_rate(dec, _gold):\n",
    "    gold = read_gold(_gold)\n",
    "    correct = 0\n",
    "    if len(gold) == len(dec):\n",
    "        for (d,g) in zip(dec, gold):\n",
    "            if d==g:\n",
    "                correct += 1\n",
    "    wrong = len(gold)-correct\n",
    "    error = wrong/len(gold)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold decipherment\n",
    "gold_file = \"data/_ref.txt\"\n",
    "ser = symbol_error_rate(decipherment, gold_file)\n",
    "print('Error: ', ser*100, 'Accuracy: ', (1-ser)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

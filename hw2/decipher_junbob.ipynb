{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Decipherment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import defaultdict, Counter\n",
    "import collections\n",
    "import pprint\n",
    "import math\n",
    "import bz2\n",
    "from ngram import *\n",
    "import sys, string\n",
    "import copy\n",
    "import pickle\n",
    "#from joblib import Parallel, delayed\n",
    "import itertools\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us read in the cipher text from the `data` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "º∫P/Z/uB∫ÀOR•–X•B\n",
      "WV+≈GyF∞ºHPπKÇ—y≈\n",
      "MJy^uIÀΩ—T‘NQyDµ£\n",
      "S¢/º∑BPORAu∫∆RÃ—E\n",
      "À^LMZJƒ“\\–FHVW≈æy\n",
      "π+—GDºKI£∞—Xæµ§S¢\n",
      "RN‘IyEÃOæ—GBTQS∑B\n",
      "Lƒ/P∑BπX—EHMu^RRÀ\n",
      "√ZK—–I£W—ÇæµLM“º∑\n",
      "BPDR+j•∞\\N¢≈EuHÀF\n",
      "Z√–OVWIµ+‘L£Ã^R∞H\n",
      "IºDR∏Ty“\\ƒ≈/πXJQA\n",
      "PµMæRu‘∫L£NVEKH•G\n",
      "“IÇJÀµºæLMÃNA£Z¢P\n",
      "§u–ÀAº∑BVW\\+VT‘OP\n",
      "^•S“Ã∆u≈∞ΩD§G∫∫IM\n",
      "NÀ£S√E/º∫∫Z∆AP∑BV\n",
      "–≈X—W—∏F∑æ√+πºAºB\n",
      "∫OTµRu√+∏ƒy—∏^S—W\n",
      "VZ≈GyKE∏TyAº∫∑L‘∏\n",
      "HÇFBXº§XADƒ\\ΩLÇ•—\n",
      "∏≈ƒ∑∑∞≈µPORXQF∫G√\n",
      "ZπJT‘—∏æJI+“BPQW∞\n",
      "VEX“ºWI∞—EHM£•uIÀ\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    if filename[-4:] == \".bz2\":\n",
    "        with bz2.open(filename, 'rt', encoding='utf8') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename, 'r', encoding='utf8') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    return content\n",
    "\n",
    "cipher = read_file(\"data/cipher.txt\")\n",
    "print(cipher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the default solution we need to compute statistics like length, number of symbols/letters, \n",
    "unique occurences, frequencies and relative frequencies of a given file. This is done in the function `get_statistics` below.\n",
    "\n",
    "While using `get_statistics`, make sure that `cipher=True` is set when the input is a ciphertext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_statistics(content, cipher=True):\n",
    "    stats = {}\n",
    "    content = list(content)\n",
    "    split_content = [x for x in content if x != '\\n' and x!=' ']\n",
    "    length = len(split_content)\n",
    "    symbols = set(split_content)\n",
    "    uniq_sym = len(list(symbols))\n",
    "    freq = collections.Counter(split_content)\n",
    "    rel_freq = {}\n",
    "    for sym, frequency in freq.items():\n",
    "        rel_freq[sym] = (frequency/length)*100\n",
    "        \n",
    "    if cipher:\n",
    "        stats = {'content':split_content, 'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    else:\n",
    "        stats = {'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ATTENTION!\n",
    "For grading purposes only. Don't bundle with the assignment. \n",
    "Make sure '_ref.txt' is removed from the 'data' directory before publishing.\n",
    "\"\"\"\n",
    "\n",
    "def read_gold(gold_file):\n",
    "    with open(gold_file) as f:\n",
    "        gold = f.read()\n",
    "    f.close()\n",
    "    gold = list(gold.strip())\n",
    "    return gold\n",
    "\n",
    "def symbol_error_rate(dec, _gold):\n",
    "    gold = read_gold(_gold)\n",
    "    correct = 0\n",
    "    if len(gold) == len(dec):\n",
    "        for (d,g) in zip(dec, gold):\n",
    "            if d==g:\n",
    "                correct += 1\n",
    "    wrong = len(gold)-correct\n",
    "    error = wrong/len(gold)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cipher_desc = get_statistics(cipher, cipher=True)\n",
    "#pp.pprint(cipher_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load the 6-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.3 s, sys: 803 ms, total: 32.1 s\n",
      "Wall time: 32.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sequence = 'In a few cases, a multilingual artifact has been necessary to facilitate decipherment, the Rosetta Stone being the classic example. Statistical techniques provide another pathway to decipherment, as does the analysis of modern languages derived from ancient languages in which undeciphered texts are written. Archaeological and historical information is helpful in verifying hypothesized decipherments.'\n",
    "\n",
    "# lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=True)\n",
    "lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a few cases, a multilingual artifact has been necessary to facilitate decipherment, the Rosetta Stone being the classic example. Statistical techniques provide another pathway to decipherment, as does the analysis of modern languages derived from ancient languages in which undeciphered texts are written. Archaeological and historical information is helpful in verifying hypothesized decipherments.\n",
      "{2: 3, 3: 4, 7: 8, 8: 9, 9: 10}\n",
      "-8.10905897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TOTAL LM LOGPROB: -221.09434842188\n",
      "TOTAL LM LOGPROB: -9.76947916\n",
      "TOTAL LM LOGPROB: -40.57683077\n"
     ]
    }
   ],
   "source": [
    "print(sequence)\n",
    "lm_logprob = lm.score_seq(sequence)\n",
    "print(\"TOTAL LM LOGPROB: {}\".format(lm_logprob), file=sys.stderr)\n",
    "print(\"TOTAL LM LOGPROB: {}\".format(lm.score_seq('this is the text.')), file=sys.stderr)\n",
    "print(\"TOTAL LM LOGPROB: {}\".format(lm.score_seq('jasbklfhthejkldhf')), file=sys.stderr)\n",
    "print(lm.get_bitstring_spans('..oo...ooo..'))\n",
    "print(lm.score_bitstring('thisisatest', 'oo...oo.ooo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "# From Yabin: new score function (should be more efficient) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_new(cipher, phi, new_f, new_e, previous_score):\n",
    "    '''\n",
    "    scores the phi_prime based on the previous score, returns a dict\n",
    "    cipher -- list of single character string\n",
    "    phi -- dictionary, old mapping e->[f]\n",
    "    new_f -- single-character string, extended symbol\n",
    "    previous_score -- float, old score for phi\n",
    "    '''\n",
    "    mapping = phi\n",
    "    new_score = previous_score\n",
    "    lm_state = lm.begin()\n",
    "    for i in range(len(cipher)):\n",
    "        char = cipher[i]\n",
    "        if char in mapping.keys():\n",
    "            token = mapping[char]\n",
    "            ngram = lm_state + (token,)\n",
    "            while len(ngram)> 0:\n",
    "                if ngram in lm.table:\n",
    "                    lm_state = ngram[-lm.history:]\n",
    "                    break\n",
    "                else: #backoff\n",
    "                    ngram = ngram[1:]\n",
    "            if len(ngram)==0:\n",
    "                lm_state = ()\n",
    "        elif char == new_f:\n",
    "            (lm_state, logprob) = lm.score(lm_state, new_e)\n",
    "            new_score += logprob\n",
    "        else:\n",
    "            lm_state = ()  \n",
    "    return new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beam_search_new(cipher, ext_order, ext_limits=1, topn=1):\n",
    "    '''\n",
    "    finds the mappings between cipher char and plaintext char, returns the mapping dictionary\n",
    "    ext_order -- list, the unigram char list sorted by their count DESC\n",
    "    ext_limits -- int, defines maximum number of cipher char can be mapped to a plaintext char\n",
    "    topn -- int, defines the number of dictionaries we want to keep while pruning\n",
    "    '''\n",
    "    print('Number of unique symbols in cipher:', len(ext_order))\n",
    "    # mapping relationships already found with score\n",
    "    Hs = [(defaultdict(dict), 0)]\n",
    "    # hypothesis mapping relationships with score\n",
    "    Ht = []\n",
    "    # initialize the cardinality (number of unique cipher text)\n",
    "    cardinality = 0\n",
    "    # list of plaintext characters\n",
    "    Ve = [chr(i) for i in range(97, 123, 1)]\n",
    "    while cardinality < len(ext_order):\n",
    "    #while cardinality < 2:\n",
    "        f = ext_order[cardinality]\n",
    "        print('Working on symbol: ', f, f'({cardinality+1})')\n",
    "        for phi, previous_score in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = copy.deepcopy(phi)\n",
    "                new_map = {f: e}\n",
    "                phi_prime.update(new_map)\n",
    "                counts = len([v for k, v in phi_prime.items() if v == e])\n",
    "                if counts <= ext_limits:\n",
    "                    Ht.append((phi_prime, score_new(cipher, phi, f, e, previous_score)))\n",
    "        # prune the histogram\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]                    \n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "        print('Current score: ', Hs[0][1])\n",
    "        #print('Hs', Hs)\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# new extension order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find(string, char):\n",
    "    return [i for i, letter in enumerate(string) if letter == char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_bit_str(cipher, deciphered_symbols):\n",
    "    # generate bit string\n",
    "    bit_string = ''\n",
    "    for char in cipher:   \n",
    "        if (char in deciphered_symbols):\n",
    "            bit_string += 'x'\n",
    "        else: \n",
    "            bit_string += '.'\n",
    "    return bit_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def case1(ngram):\n",
    "    #print(\"case 1\")\n",
    "    num_pos = np.zeros(ngram)\n",
    "    num_pos[0] += 1\n",
    "    return num_pos\n",
    "def case2(ngram, str_after):\n",
    "    #print(\"case 2\")\n",
    "    num_pos = np.zeros(ngram)\n",
    "    if str_after.find('.') != -1:\n",
    "        str_after = str_after[:str_after.find('.')]\n",
    "    #print(\"after1: \"+str_after)\n",
    "    for i in range(len(str_after)):\n",
    "        idx = i+1\n",
    "        num_pos[idx] += 1\n",
    "        if idx+1 == ngram:\n",
    "            break    \n",
    "    return num_pos\n",
    "def case3(ngram, str_before):\n",
    "    #print(\"case 3\")\n",
    "    num_pos = np.zeros(ngram)\n",
    "    str_before = str_before[str_before.rfind('.')+1:]\n",
    "    #print(\"before1: \"+str_before)\n",
    "    for i in range(len(str_before)):\n",
    "        idx = i+1\n",
    "        num_pos[idx] += 1\n",
    "        if idx+1 == ngram:\n",
    "            break\n",
    "    return num_pos\n",
    "def case4(ngram, str_before, str_after):  \n",
    "    #print(\"case 4\")\n",
    "    num_pos = np.zeros(ngram)\n",
    "    str_before = str_before[str_before.rfind('.')+1:]\n",
    "    if str_after.find('.') != -1:\n",
    "        str_after = str_after[:str_after.find('.')]\n",
    "    #print(\"before1: \"+str_before)\n",
    "    #print(\"after1: \"+str_after)\n",
    "    num_pos[0] -= 1\n",
    "    for i in range(len(str_before)):\n",
    "        idx = i+1\n",
    "        num_pos[idx] += 1\n",
    "        if idx+1 == ngram:\n",
    "            break    \n",
    "    for i in range(len(str_after)):\n",
    "        idx = i+1\n",
    "        num_pos[idx] += 1\n",
    "        if idx+1 == ngram:\n",
    "            break    \n",
    "            \n",
    "    # ********* to be complete ********* #\n",
    "    \n",
    "    return num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ext_order(cipher, topn=100, weights=(1.0, 1.0, 1.0, 1.0, 2.0, 3.0), ngram = 6):\n",
    "\n",
    "    # initial\n",
    "    cipher_desc = get_statistics(cipher, cipher=True)\n",
    "    weights = np.array(weights)\n",
    "    cipher_vocab = cipher_desc['vocab']\n",
    "\n",
    "    first_symbol = cipher_desc['frequencies'].most_common(1)[0][0] # use the most frequent symbol as first symbol\n",
    "    \n",
    "    cardinality = 1\n",
    "    \n",
    "    # symbols already found with score\n",
    "    Hs = [([first_symbol], 0)]\n",
    "    # hypothesis extended symbols with score\n",
    "    Ht = []\n",
    "    \n",
    "    print('Done with symbol number', cardinality, '; Current best score: ', Hs[0][1])\n",
    "    \n",
    "    while cardinality < cipher_desc['vocab_length']:\n",
    "        for phi, previous_score in Hs:\n",
    "            \n",
    "            deciphered_symbols = phi\n",
    "            bit_string = gen_bit_str(cipher, deciphered_symbols)\n",
    "            \n",
    "            for voc in cipher_vocab:\n",
    "                phi_prime = copy.deepcopy(phi)\n",
    "                if voc in phi_prime:\n",
    "                    continue\n",
    "                else:\n",
    "                    weighted_sum = 0.0\n",
    "                    num_pos = np.zeros(ngram)\n",
    "                    # for every occurance, \n",
    "                    for pos in find(cipher, voc):\n",
    "                        str_before = bit_string[0:pos]\n",
    "                        str_after = bit_string[pos+1:]\n",
    "                        #print(\"before: \"+str_before) \n",
    "                        #print(\"after: \"+str_after) \n",
    "\n",
    "                        if len(str_before) == 0:\n",
    "                            if str_after[0] == '.':\n",
    "                                num_pos += case1(ngram)\n",
    "                            else:\n",
    "                                num_pos += case2(ngram, str_after)\n",
    "                        elif len(str_after) == 0:\n",
    "                            if str_before[-1] == '.':\n",
    "                                num_pos += case1(ngram)\n",
    "                            else:\n",
    "                                num_pos += case3(ngram, str_before)\n",
    "                        elif (str_before[-1] == '.') and (str_after[0] == '.'):\n",
    "                            num_pos += case1(ngram)\n",
    "                        elif (str_before[-1] == '.') and (str_after[0] == 'x'):\n",
    "                            num_pos += case2(ngram, str_after)\n",
    "                        elif (str_before[-1] == 'x') and (str_after[0] == '.'):\n",
    "                            num_pos += case3(ngram, str_before)\n",
    "                        else:\n",
    "                            num_pos += case4(ngram, str_before, str_after)\n",
    "\n",
    "                    weighted_sum += np.sum(np.multiply(weights, num_pos))\n",
    "                    #print(\"weighted_sum: \" + str(weighted_sum))\n",
    "                    \n",
    "                    phi_prime.append(voc)\n",
    "                    this_score = previous_score + weighted_sum\n",
    "                    Ht.append((phi_prime, this_score))\n",
    "        \n",
    "        # prune the histogram\n",
    "        Ht = sorted(Ht, key=lambda x:x[1], reverse=True)[:topn]\n",
    "        cardinality += 1\n",
    "        Hs = copy.deepcopy(Ht)\n",
    "        Ht.clear()\n",
    "        \n",
    "        print('Done with symbol number', cardinality, '; Current best score: ', Hs[0][1], '; Current worst score: ', Hs[-1][1])\n",
    "    return sorted(Hs, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with symbol number 1 ; Current best score:  0\n",
      "Done with symbol number 2 ; Current best score:  14.0 ; Current worst score:  1.0\n",
      "Done with symbol number 3 ; Current best score:  26.0 ; Current worst score:  16.0\n",
      "Done with symbol number 4 ; Current best score:  38.0 ; Current worst score:  33.0\n",
      "Done with symbol number 5 ; Current best score:  53.0 ; Current worst score:  47.0\n",
      "Done with symbol number 6 ; Current best score:  67.0 ; Current worst score:  61.0\n",
      "Done with symbol number 7 ; Current best score:  84.0 ; Current worst score:  77.0\n",
      "Done with symbol number 8 ; Current best score:  104.0 ; Current worst score:  95.0\n",
      "Done with symbol number 9 ; Current best score:  121.0 ; Current worst score:  113.0\n",
      "Done with symbol number 10 ; Current best score:  141.0 ; Current worst score:  132.0\n",
      "Done with symbol number 11 ; Current best score:  162.0 ; Current worst score:  154.0\n",
      "Done with symbol number 12 ; Current best score:  186.0 ; Current worst score:  176.0\n",
      "Done with symbol number 13 ; Current best score:  209.0 ; Current worst score:  199.0\n",
      "Done with symbol number 14 ; Current best score:  230.0 ; Current worst score:  223.0\n",
      "Done with symbol number 15 ; Current best score:  253.0 ; Current worst score:  246.0\n",
      "Done with symbol number 16 ; Current best score:  270.0 ; Current worst score:  267.0\n",
      "Done with symbol number 17 ; Current best score:  288.0 ; Current worst score:  284.0\n",
      "Done with symbol number 18 ; Current best score:  309.0 ; Current worst score:  302.0\n",
      "Done with symbol number 19 ; Current best score:  329.0 ; Current worst score:  324.0\n",
      "Done with symbol number 20 ; Current best score:  352.0 ; Current worst score:  346.0\n",
      "Done with symbol number 21 ; Current best score:  371.0 ; Current worst score:  368.0\n",
      "Done with symbol number 22 ; Current best score:  393.0 ; Current worst score:  390.0\n",
      "Done with symbol number 23 ; Current best score:  414.0 ; Current worst score:  411.0\n",
      "Done with symbol number 24 ; Current best score:  437.0 ; Current worst score:  432.0\n",
      "Done with symbol number 25 ; Current best score:  462.0 ; Current worst score:  455.0\n",
      "Done with symbol number 26 ; Current best score:  491.0 ; Current worst score:  481.0\n",
      "Done with symbol number 27 ; Current best score:  514.0 ; Current worst score:  509.0\n",
      "Done with symbol number 28 ; Current best score:  542.0 ; Current worst score:  537.0\n",
      "Done with symbol number 29 ; Current best score:  568.0 ; Current worst score:  566.0\n",
      "Done with symbol number 30 ; Current best score:  604.0 ; Current worst score:  594.0\n",
      "Done with symbol number 31 ; Current best score:  633.0 ; Current worst score:  626.0\n",
      "Done with symbol number 32 ; Current best score:  665.0 ; Current worst score:  660.0\n",
      "Done with symbol number 33 ; Current best score:  701.0 ; Current worst score:  692.0\n",
      "Done with symbol number 34 ; Current best score:  729.0 ; Current worst score:  727.0\n",
      "Done with symbol number 35 ; Current best score:  764.0 ; Current worst score:  759.0\n",
      "Done with symbol number 36 ; Current best score:  800.0 ; Current worst score:  795.0\n",
      "Done with symbol number 37 ; Current best score:  841.0 ; Current worst score:  832.0\n",
      "Done with symbol number 38 ; Current best score:  878.0 ; Current worst score:  872.0\n",
      "Done with symbol number 39 ; Current best score:  919.0 ; Current worst score:  914.0\n",
      "Done with symbol number 40 ; Current best score:  972.0 ; Current worst score:  965.0\n",
      "Done with symbol number 41 ; Current best score:  1015.0 ; Current worst score:  1008.0\n",
      "Done with symbol number 42 ; Current best score:  1052.0 ; Current worst score:  1051.0\n",
      "Done with symbol number 43 ; Current best score:  1095.0 ; Current worst score:  1093.0\n",
      "Done with symbol number 44 ; Current best score:  1137.0 ; Current worst score:  1133.0\n",
      "Done with symbol number 45 ; Current best score:  1179.0 ; Current worst score:  1178.0\n",
      "Done with symbol number 46 ; Current best score:  1220.0 ; Current worst score:  1220.0\n",
      "Done with symbol number 47 ; Current best score:  1262.0 ; Current worst score:  1261.0\n",
      "Done with symbol number 48 ; Current best score:  1303.0 ; Current worst score:  1303.0\n",
      "Done with symbol number 49 ; Current best score:  1342.0 ; Current worst score:  1342.0\n",
      "Done with symbol number 50 ; Current best score:  1379.0 ; Current worst score:  1379.0\n",
      "Done with symbol number 51 ; Current best score:  1418.0 ; Current worst score:  1418.0\n",
      "Done with symbol number 52 ; Current best score:  1460.0 ; Current worst score:  1460.0\n",
      "Done with symbol number 53 ; Current best score:  1496.0 ; Current worst score:  1496.0\n",
      "Done with symbol number 54 ; Current best score:  1511.0 ; Current worst score:  1511.0\n",
      "CPU times: user 3min 36s, sys: 499 ms, total: 3min 36s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test the function above\n",
    "ext_order = find_ext_order(cipher, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sorted_keys = sorted(cipher_desc['frequencies'], key=cipher_desc['frequencies'].get, reverse=True)\n",
    "#reversed_mappings = beam_search(cipher_desc['content'], sorted_keys, 3, 100)\n",
    "#reversed_mappings = beam_search(cipher_desc['content'], right_most_cipher_vocab, 8, 1000)\n",
    "mappings = beam_search_new(cipher_desc['content'], ext_order[0][0], 8, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = mappings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decipher_text = ''\n",
    "for char in cipher_desc['content']:\n",
    "    decipher_text += mapping[char]\n",
    "print(decipher_text)\n",
    "print('score', lm.score_seq(decipher_text))\n",
    "print(len(decipher_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/_ref_Zodiac_408.txt', 'r') as fh:\n",
    "    ground_truth = fh.read()\n",
    "print(ground_truth)\n",
    "print('score', lm.score_seq(ground_truth))\n",
    "print(len(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_error_rate(decipher_text, 'data/_ref_Zodiac_408.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

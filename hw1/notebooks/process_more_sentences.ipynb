{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and process more sentences from the same distribution as the devset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentences source: Monty Python and The Holy Grail\n",
    "#### http://www.castlebar.ie/board/msgjan2001/22833.htm\n",
    "\n",
    "**Steps:**\n",
    ">**1. Manually copy new sentences to a local file.**<br>\n",
    ">**2. Correct wrong person names and some formating issues both programmingly and manually.**<br>\n",
    ">**3. Check if all the words is in the allowed words file.**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct wrong person names and some formating issues. <br>\n",
    "Manual replacements:\n",
    ">Tiogar -> Zoot <br>\n",
    ">Idiotic trivia -> Concorde <br>\n",
    ">melmacs -> keepers <br>\n",
    ">melmac -> keeper <br>\n",
    ">Melmac -> Old man <br>\n",
    ">Times. -> Tim the Enchanter <br>\n",
    ">Fortycoats -> Maynard <br>\n",
    ">Jesus el christos -> Father <br>\n",
    ">Baloo -> Herbert <br>\n",
    ">Chaz -> Dingo <br>\n",
    ">illegitimes .Dougalate faced -> illegitimate faced <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pruncList = ['.', '?', '!', ',', '-', \"'\"]\n",
    "file3 = open('quotes_new.txt', 'r')\n",
    "file4 = open('quotes_new_preprocessed.txt', 'w')\n",
    "for i in file3:\n",
    "    if not (i.startswith(\"Scene\") or i.startswith(\"[\")) :\n",
    "        pos = i.find(':')\n",
    "        txt = i.strip()\n",
    "        wrt = ''\n",
    "        if (pos != -1) and (len(txt)!=0) and (txt[-1]!=':'):\n",
    "            wrt = i[pos+1:].strip()\n",
    "        else:\n",
    "            wrt = i.strip()\n",
    "        if (len(txt)!=0) and (wrt[-1] not in pruncList):\n",
    "            wrt = wrt+' '\n",
    "            \n",
    "        wrt = wrt.replace('...', ' $$$\\n').replace('....', ' $$$$\\n').replace('.', ' .\\n')\\\n",
    "        .replace('!', ' !\\n').replace('?', ' ?\\n').replace('\\n ', '\\n')\\\n",
    "        .replace(',', ' ,').replace('$', '.').replace(' -- ', '--').replace('--', ' -- ')\\\n",
    "        .replace('Bulletin board posters', 'Britons').replace('Scrawny', 'Arthur')\\\n",
    "        .replace('Voodoo Child', 'Patsy').replace('Pete Jordan', 'Dennis')\\\n",
    "        .replace('Kharn', 'Bedemir').replace('Fr ', 'times').replace('Moderator', 'God')\\\n",
    "        .replace('jesus el christos', 'father').replace('Luca Brasi', 'Launcelot')\\\n",
    "        .replace('Buzz', 'Galahad').replace('Spartacus', 'Robin').replace('Dougales', '')\\\n",
    "        .replace('EN', 'Black Knight').replace('Dougale', '')\\\n",
    "        .replace(\"'d\", \" 'd\").replace(\"'em\", \" 'em\").replace(\"'ll\", \" 'll\")\\\n",
    "        .replace(\"'ow\", \" 'ow\").replace(\"'re\", \" 're\").replace(\"'s\", \" 's\").replace(\"'ve\", \" 've\")\\\n",
    "        .replace(\"n't\", \" n't\").replace(\"y'\", \"y' \").replace(\"d'\", \"d' \").replace(\"`\", \"` \")\\\n",
    "        .replace(\"we 're\", \"we're\").replace(\"We 're\", \"We're\").replace(\"You 're\", \"You're\")\\\n",
    "        .replace(\"you 're\", \"you're\").replace(\"We 've\", \"We've\").replace(\"we 've\", \"we've\")\\\n",
    "        .replace(\"I 've\", \"I've\").replace(\"ca n't\", \"can't\")\n",
    "        \n",
    "        if('--' not in wrt):\n",
    "            wrt = wrt.replace('-', ' - ')\n",
    "        file4.write(wrt)\n",
    "\n",
    "file3.close()\n",
    "file4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all the words are in the allowed words file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_words = []\n",
    "file6 = open('allowed_words.txt', 'r')\n",
    "for i in file6:\n",
    "    allowed_words.append(i.strip())\n",
    "file6.close()\n",
    "\n",
    "count = 0\n",
    "checked = True\n",
    "file5 = open('quotes_new_preprocessed.txt', 'r')\n",
    "for i in file5:\n",
    "    sentence = i.strip().split(' ')\n",
    "    count+=1\n",
    "    for word in sentence:\n",
    "        word2 = word.strip()\n",
    "        if (word2 != '') and (word2 not in allowed_words):\n",
    "            print(count)\n",
    "            print(word2)\n",
    "            checked = False\n",
    "file5.close()\n",
    "if checked:\n",
    "    print(\"All words are in the allowed words file. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
